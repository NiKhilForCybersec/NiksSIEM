<!DOCTYPE html>
<html lang="en" data-theme="dark" data-platform="sentinel">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Parsing Flows - End-to-End Log Processing | Nik's SIEM</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="../assets/css/main.css">
    <style>
        .flow-diagram { background: var(--card-bg); padding: 1.5rem; border-radius: 8px; margin: 1rem 0; font-family: monospace; font-size: 0.75rem; overflow-x: auto; }
        .flow-step { display: flex; align-items: center; gap: 1rem; padding: 1rem; background: rgba(0,120,212,0.1); border-radius: 8px; margin: 0.5rem 0; }
        .flow-step-number { background: #0078d4; color: white; width: 30px; height: 30px; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-weight: bold; flex-shrink: 0; }
        .flow-arrow { color: #0078d4; font-size: 1.5rem; text-align: center; padding: 0.5rem 0; }
        .log-source-card { border-left: 4px solid #0078d4; padding: 1rem; background: var(--card-bg); border-radius: 0 8px 8px 0; margin: 1rem 0; }
    </style>
</head>
<body>
    <div class="app-container">
                <aside class="sidebar">
            <div class="sidebar-header">
                <a href="../index.html" class="sidebar-brand">
                    <div class="brand-icon"><i class="fas fa-shield-halved"></i></div>
                    <div class="brand-text">
                        <span class="brand-title">Nik's SIEM</span>
                        <span class="brand-subtitle">SIEM Reference Guide</span>
                    </div>
                </a>
            </div>

            <div class="platform-selector">
                <div class="platform-tabs">
                    <a href="../xsiam/index.html" class="platform-tab xsiam"><i class="fas fa-fire"></i> XSIAM</a>
                    <a href="../sentinel/index.html" class="platform-tab sentinel active"><i class="fas fa-shield-alt"></i> Sentinel</a>
                    <a href="../splunk/index.html" class="platform-tab splunk"><i class="fas fa-search"></i> Splunk</a>
                    <a href="../mde/index.html" class="platform-tab mde"><i class="fas fa-desktop"></i> MDE</a>
                </div>
            </div>
<nav class="sidebar-nav">
                <div class="nav-section">
                    <div class="nav-section-title">Getting Started</div>
                    <a href="index.html" class="nav-link"><i class="fas fa-home"></i> Overview</a>
                    <a href="architecture.html" class="nav-link"><i class="fas fa-sitemap"></i> Architecture</a>
                </div>
                <div class="nav-section">
                    <div class="nav-section-title">Data Collection</div>
                    <a href="data-connectors.html" class="nav-link"><i class="fas fa-plug"></i> Data Connectors</a>
                    <a href="dcr-dce-guide.html" class="nav-link"><i class="fas fa-cogs"></i> DCR & DCE Deep Dive</a>
                    <a href="event-hub.html" class="nav-link"><i class="fas fa-broadcast-tower"></i> Event Hub Integration</a>
                    <a href="data-ingestion.html" class="nav-link"><i class="fas fa-database"></i> Ingestion & Cost</a>
                    <a href="parsing-flows.html" class="nav-link active"><i class="fas fa-stream"></i> Parsing Flows</a>
                </div>
                <div class="nav-section">
                    <div class="nav-section-title">KQL Query Language</div>
                    <a href="kql-fundamentals.html" class="nav-link"><i class="fas fa-terminal"></i> KQL Fundamentals</a>
                    <a href="kql-intermediate.html" class="nav-link"><i class="fas fa-layer-group"></i> KQL Intermediate</a>
                    <a href="kql-advanced.html" class="nav-link"><i class="fas fa-code"></i> Advanced KQL</a>
                </div>
                <div class="nav-section">
                    <div class="nav-section-title">Detection & Response</div>
                    <a href="analytics-rules.html" class="nav-link"><i class="fas fa-bell"></i> Analytics Rules</a>
                    <a href="automation.html" class="nav-link"><i class="fas fa-robot"></i> Automation</a>
                    <a href="workbooks.html" class="nav-link"><i class="fas fa-chart-bar"></i> Workbooks</a>
                </div>
                <div class="nav-section">
                    <div class="nav-section-title">Content & Intelligence</div>
                    <a href="content-hub.html" class="nav-link"><i class="fas fa-cube"></i> Content Hub & ASIM</a>
                    <a href="threat-intel.html" class="nav-link"><i class="fas fa-crosshairs"></i> Threat Intelligence</a>
                </div>
                <div class="nav-section">
                    <div class="nav-section-title">Reference</div>
                    <a href="enterprise-scenarios.html" class="nav-link"><i class="fas fa-building"></i> Enterprise Scenarios</a>
                    <a href="soc-operations.html" class="nav-link"><i class="fas fa-users-cog"></i> SOC Operations</a>
                </div>
            </nav>
        </aside>
        
        <div class="main-wrapper">
            <header class="top-bar">
                <div class="breadcrumb">
                    <a href="../index.html">Home</a>
                    <span class="separator">/</span>
                    <a href="index.html">Sentinel</a>
                    <span class="separator">/</span>
                    <span class="current">Parsing Flows</span>
                </div>
            </header>
            
            <main class="main-content">
                <div class="page-header">
                    <h1><i class="fas fa-stream"></i> End-to-End Parsing Flows</h1>
                    <p class="lead">Complete data journey from source to queryable table - understanding exactly what happens at each stage for different log sources</p>
                </div>

                <!-- Overview -->
                <section class="content-section">
                    <h2><i class="fas fa-map"></i> Understanding the Data Journey</h2>
                    
                    <p>Every log that reaches Sentinel goes through a specific pipeline. Understanding this pipeline helps you troubleshoot issues, optimize costs, and build better detections.</p>

                    <div class="flow-diagram">
<pre>
┌─────────────────────────────────────────────────────────────────────────────────────┐
│                    SENTINEL DATA PROCESSING PIPELINE                                │
├─────────────────────────────────────────────────────────────────────────────────────┤
│                                                                                      │
│   SOURCE              COLLECTION           TRANSFORMATION        STORAGE            │
│                                                                                      │
│  ┌─────────┐        ┌─────────────┐       ┌─────────────┐      ┌─────────────┐     │
│  │ Windows │───────▶│ AMA + DCR   │──────▶│ DCR         │─────▶│ Security    │     │
│  │ Server  │        │             │       │ transformKql│      │ Event       │     │
│  └─────────┘        └─────────────┘       └─────────────┘      └─────────────┘     │
│                                                                       │             │
│  ┌─────────┐        ┌─────────────┐       ┌─────────────┐            │             │
│  │ Linux   │───────▶│ AMA + DCR   │──────▶│ Built-in    │─────▶  Syslog          │
│  │ Server  │        │ (Syslog)    │       │ parsing     │                         │
│  └─────────┘        └─────────────┘       └─────────────┘                         │
│                                                                       │             │
│  ┌─────────┐        ┌─────────────┐       ┌─────────────┐            │             │
│  │ Firewall│───────▶│ CEF/Syslog  │──────▶│ CEF Parser  │─────▶  CommonSecurity  │
│  │ (CEF)   │        │ Forwarder   │       │             │          Log            │
│  └─────────┘        └─────────────┘       └─────────────┘                         │
│                                                                       │             │
│  ┌─────────┐        ┌─────────────┐       ┌─────────────┐            ▼             │
│  │ Azure   │───────▶│ Diagnostic  │──────▶│ Workspace   │      ┌─────────────┐    │
│  │ Service │        │ Settings    │       │ Transform   │      │ ASIM Parser │    │
│  └─────────┘        └─────────────┘       │ DCR         │      │ (Query-time)│    │
│                                           └─────────────┘      └─────────────┘    │
│  ┌─────────┐        ┌─────────────┐       ┌─────────────┐                         │
│  │ Custom  │───────▶│ Logs        │──────▶│ DCR with    │─────▶  Custom_CL       │
│  │ App     │        │ Ingestion   │       │ Schema      │                         │
│  └─────────┘        │ API + DCE   │       │             │                         │
│                     └─────────────┘       └─────────────┘                         │
│                                                                                      │
└─────────────────────────────────────────────────────────────────────────────────────┘
</pre>
                    </div>
                </section>

                <!-- Flow 1: Windows Security Events -->
                <section class="content-section">
                    <h2><i class="fab fa-windows"></i> Flow 1: Windows Security Events (AMA)</h2>
                    
                    <div class="log-source-card">
                        <h4>Source: Windows Server Domain Controller</h4>
                        <p><strong>Target Table:</strong> SecurityEvent</p>
                        <p><strong>Parsing:</strong> Built-in (Microsoft)</p>
                        <p><strong>Normalization:</strong> ASIM Authentication parser available</p>
                    </div>

                    <h3>End-to-End Flow</h3>

                    <div class="flow-step">
                        <div class="flow-step-number">1</div>
                        <div>
                            <strong>Source Generation</strong><br>
                            Windows generates Security Event (e.g., EventID 4624 - Successful Logon)<br>
                            <code>Event written to Security.evtx on local disk</code>
                        </div>
                    </div>
                    <div class="flow-arrow">↓</div>

                    <div class="flow-step">
                        <div class="flow-step-number">2</div>
                        <div>
                            <strong>AMA Collection</strong><br>
                            Azure Monitor Agent reads events matching DCR XPath query<br>
                            <code>XPath: Security!*[System[(EventID=4624 or EventID=4625)]]</code>
                        </div>
                    </div>
                    <div class="flow-arrow">↓</div>

                    <div class="flow-step">
                        <div class="flow-step-number">3</div>
                        <div>
                            <strong>DCR Processing</strong><br>
                            DCR applies transformKql (if configured) to filter/modify<br>
                            <code>source | where AccountType != "Machine"</code>
                        </div>
                    </div>
                    <div class="flow-arrow">↓</div>

                    <div class="flow-step">
                        <div class="flow-step-number">4</div>
                        <div>
                            <strong>Table Storage</strong><br>
                            Data stored in SecurityEvent table with parsed fields<br>
                            <code>EventID, Account, Computer, LogonType, etc.</code>
                        </div>
                    </div>
                    <div class="flow-arrow">↓</div>

                    <div class="flow-step">
                        <div class="flow-step-number">5</div>
                        <div>
                            <strong>Query-Time (Optional)</strong><br>
                            ASIM parser normalizes for cross-source correlation<br>
                            <code>_Im_Authentication | where EventResult == "Failure"</code>
                        </div>
                    </div>

                    <h3>Complete Configuration</h3>

                    <div class="code-block">
                        <div class="code-header">
                            <span class="code-lang">JSON</span>
                            <span class="code-title">DCR for Windows Security Events</span>
                        </div>
                        <pre><code>{
  "properties": {
    "dataSources": {
      "windowsEventLogs": [{
        "name": "SecurityEventCollection",
        "streams": ["Microsoft-SecurityEvent"],
        "xPathQueries": [
          "Security!*[System[(EventID=4624)]]",
          "Security!*[System[(EventID=4625)]]",
          "Security!*[System[(EventID=4648)]]",
          "Security!*[System[(EventID=4672)]]",
          "Security!*[System[(EventID=4688)]]",
          "Security!*[System[(EventID &gt;= 4720 and EventID &lt;= 4735)]]"
        ]
      }]
    },
    "dataFlows": [{
      "streams": ["Microsoft-SecurityEvent"],
      "destinations": ["SentinelWorkspace"],
      "transformKql": "source | where not(EventID == 4688 and NewProcessName contains 'svchost')"
    }]
  }
}</code></pre>
                    </div>

                    <div class="code-block">
                        <div class="code-header">
                            <span class="code-lang">KQL</span>
                            <span class="code-title">Query Examples</span>
                        </div>
                        <pre><code>// Direct table query
SecurityEvent
| where TimeGenerated > ago(1h)
| where EventID == 4625
| project TimeGenerated, Account, Computer, LogonType, FailureReason

// Using ASIM normalized parser
_Im_Authentication(starttime=ago(1h))
| where EventResult == "Failure"
| summarize FailedAttempts = count() by TargetUsername, SrcIpAddr
| where FailedAttempts > 5</code></pre>
                    </div>
                </section>

                <!-- Flow 2: Linux Syslog -->
                <section class="content-section">
                    <h2><i class="fab fa-linux"></i> Flow 2: Linux Syslog (AMA)</h2>
                    
                    <div class="log-source-card">
                        <h4>Source: Linux Server (Ubuntu/RHEL)</h4>
                        <p><strong>Target Table:</strong> Syslog</p>
                        <p><strong>Parsing:</strong> Built-in syslog parsing</p>
                        <p><strong>Key Fields:</strong> Facility, SeverityLevel, ProcessName, SyslogMessage</p>
                    </div>

                    <h3>End-to-End Flow</h3>

                    <div class="flow-step">
                        <div class="flow-step-number">1</div>
                        <div>
                            <strong>Source Generation</strong><br>
                            Application writes to syslog (auth.log, syslog, etc.)<br>
                            <code>logger -p auth.info "User jsmith logged in"</code>
                        </div>
                    </div>
                    <div class="flow-arrow">↓</div>

                    <div class="flow-step">
                        <div class="flow-step-number">2</div>
                        <div>
                            <strong>rsyslog/syslog-ng</strong><br>
                            Local syslog daemon receives message<br>
                            Writes to /var/log/ and forwards to AMA socket
                        </div>
                    </div>
                    <div class="flow-arrow">↓</div>

                    <div class="flow-step">
                        <div class="flow-step-number">3</div>
                        <div>
                            <strong>AMA Collection</strong><br>
                            AMA reads from syslog socket based on DCR facility/severity filters<br>
                            <code>Facilities: auth, authpriv | Levels: Warning, Error, Critical</code>
                        </div>
                    </div>
                    <div class="flow-arrow">↓</div>

                    <div class="flow-step">
                        <div class="flow-step-number">4</div>
                        <div>
                            <strong>Syslog Table</strong><br>
                            Data stored with parsed fields<br>
                            <code>TimeGenerated, Computer, Facility, SeverityLevel, ProcessName, SyslogMessage</code>
                        </div>
                    </div>

                    <h3>Complete Configuration</h3>

                    <div class="code-block">
                        <div class="code-header">
                            <span class="code-lang">JSON</span>
                            <span class="code-title">DCR for Linux Syslog</span>
                        </div>
                        <pre><code>{
  "properties": {
    "dataSources": {
      "syslog": [
        {
          "name": "AuthenticationLogs",
          "streams": ["Microsoft-Syslog"],
          "facilityNames": ["auth", "authpriv"],
          "logLevels": ["Debug", "Info", "Notice", "Warning", "Error", "Critical", "Alert", "Emergency"]
        },
        {
          "name": "SystemLogs",
          "streams": ["Microsoft-Syslog"],
          "facilityNames": ["syslog", "daemon", "kern"],
          "logLevels": ["Warning", "Error", "Critical", "Alert", "Emergency"]
        }
      ]
    },
    "dataFlows": [{
      "streams": ["Microsoft-Syslog"],
      "destinations": ["SentinelWorkspace"],
      "transformKql": "source | where ProcessName != 'CRON'"
    }]
  }
}</code></pre>
                    </div>

                    <div class="code-block">
                        <div class="code-header">
                            <span class="code-lang">Bash</span>
                            <span class="code-title">rsyslog Configuration for AMA</span>
                        </div>
                        <pre><code># /etc/rsyslog.d/10-azuremonitoragent.conf
# Forward auth logs to AMA
auth,authpriv.*  @127.0.0.1:28330

# Or use the recommended omuxsock for reliability
module(load="omuxsock")
action(type="omuxsock" Socket="/run/azuremonitoragent/default_syslog.socket")</code></pre>
                    </div>
                </section>

                <!-- Flow 3: CEF/Syslog from Firewall -->
                <section class="content-section">
                    <h2><i class="fas fa-fire"></i> Flow 3: CEF from Network Devices (Firewall/Proxy)</h2>
                    
                    <div class="log-source-card">
                        <h4>Source: Palo Alto / Fortinet / Check Point Firewall</h4>
                        <p><strong>Target Table:</strong> CommonSecurityLog</p>
                        <p><strong>Parsing:</strong> Built-in CEF parser</p>
                        <p><strong>Format:</strong> CEF (Common Event Format) over Syslog</p>
                    </div>

                    <h3>End-to-End Flow</h3>

                    <div class="flow-step">
                        <div class="flow-step-number">1</div>
                        <div>
                            <strong>Firewall Generates Log</strong><br>
                            Traffic/threat event formatted as CEF<br>
                            <code>CEF:0|PaloAlto|NGFW|10.0|TRAFFIC|end|3|src=192.168.1.100 dst=8.8.8.8...</code>
                        </div>
                    </div>
                    <div class="flow-arrow">↓</div>

                    <div class="flow-step">
                        <div class="flow-step-number">2</div>
                        <div>
                            <strong>Syslog to Forwarder VM</strong><br>
                            Firewall sends syslog to Linux forwarder VM<br>
                            <code>rsyslog receives on UDP/TCP 514</code>
                        </div>
                    </div>
                    <div class="flow-arrow">↓</div>

                    <div class="flow-step">
                        <div class="flow-step-number">3</div>
                        <div>
                            <strong>AMA on Forwarder</strong><br>
                            AMA collects CEF messages via DCR<br>
                            <code>DCR configured for CEF data source</code>
                        </div>
                    </div>
                    <div class="flow-arrow">↓</div>

                    <div class="flow-step">
                        <div class="flow-step-number">4</div>
                        <div>
                            <strong>CEF Parser</strong><br>
                            Built-in parser extracts CEF fields<br>
                            <code>DeviceVendor, DeviceProduct, SourceIP, DestinationIP, etc.</code>
                        </div>
                    </div>
                    <div class="flow-arrow">↓</div>

                    <div class="flow-step">
                        <div class="flow-step-number">5</div>
                        <div>
                            <strong>CommonSecurityLog Table</strong><br>
                            Structured data stored with ~100 standard CEF fields<br>
                            <code>Query: CommonSecurityLog | where DeviceVendor == "PaloAlto"</code>
                        </div>
                    </div>

                    <h3>Forwarder VM Setup</h3>

                    <div class="code-block">
                        <div class="code-header">
                            <span class="code-lang">Bash</span>
                            <span class="code-title">Configure Linux VM as CEF Forwarder</span>
                        </div>
                        <pre><code># 1. Install AMA on the Linux VM (via Azure Portal or CLI)
# VM must be Azure VM or Azure Arc-enabled

# 2. Configure rsyslog to receive external syslog
# /etc/rsyslog.conf - enable UDP/TCP reception
module(load="imudp")
input(type="imudp" port="514")

module(load="imtcp")
input(type="imtcp" port="514")

# 3. Forward CEF to AMA
# /etc/rsyslog.d/10-cef-ama.conf
if $rawmsg contains "CEF:" then {
    action(type="omfwd" target="127.0.0.1" port="28330" protocol="tcp")
    stop
}

# 4. Restart rsyslog
sudo systemctl restart rsyslog

# 5. Create DCR in Azure Portal
# Data Source: Common Event Format (CEF)
# Facility: Local (or match your firewall config)
# Levels: All (or as needed)</code></pre>
                    </div>

                    <div class="info-box">
                        <h4>CEF Field Mapping</h4>
                        <table class="styled-table">
                            <tr><th>CEF Field</th><th>CommonSecurityLog Column</th><th>Example Value</th></tr>
                            <tr><td>src</td><td>SourceIP</td><td>192.168.1.100</td></tr>
                            <tr><td>dst</td><td>DestinationIP</td><td>8.8.8.8</td></tr>
                            <tr><td>spt</td><td>SourcePort</td><td>54321</td></tr>
                            <tr><td>dpt</td><td>DestinationPort</td><td>443</td></tr>
                            <tr><td>act</td><td>DeviceAction</td><td>allow</td></tr>
                            <tr><td>cs1-cs6</td><td>DeviceCustomString1-6</td><td>Vendor-specific</td></tr>
                        </table>
                    </div>
                </section>

                <!-- Flow 4: Custom Application Logs -->
                <section class="content-section">
                    <h2><i class="fas fa-code"></i> Flow 4: Custom Application Logs (Logs Ingestion API)</h2>
                    
                    <div class="log-source-card">
                        <h4>Source: In-House Web Application</h4>
                        <p><strong>Target Table:</strong> Custom_AppLogs_CL</p>
                        <p><strong>Parsing:</strong> Custom DCR transformation</p>
                        <p><strong>Method:</strong> REST API via Azure Function</p>
                    </div>

                    <h3>End-to-End Flow</h3>

                    <div class="flow-step">
                        <div class="flow-step-number">1</div>
                        <div>
                            <strong>Application Generates Log</strong><br>
                            App writes JSON log to file or queue<br>
                            <code>{"timestamp":"2025-01-15T10:30:00Z","level":"ERROR","user":"jsmith",...}</code>
                        </div>
                    </div>
                    <div class="flow-arrow">↓</div>

                    <div class="flow-step">
                        <div class="flow-step-number">2</div>
                        <div>
                            <strong>Azure Function Triggered</strong><br>
                            Timer or Event Grid triggers Function<br>
                            <code>Reads logs from source (blob, queue, file)</code>
                        </div>
                    </div>
                    <div class="flow-arrow">↓</div>

                    <div class="flow-step">
                        <div class="flow-step-number">3</div>
                        <div>
                            <strong>POST to DCE</strong><br>
                            Function sends JSON to Data Collection Endpoint<br>
                            <code>POST https://dce-xxx.ingest.monitor.azure.com/...streams/Custom-AppLogs_CL</code>
                        </div>
                    </div>
                    <div class="flow-arrow">↓</div>

                    <div class="flow-step">
                        <div class="flow-step-number">4</div>
                        <div>
                            <strong>DCR Transformation</strong><br>
                            DCR applies transformKql to enrich/normalize<br>
                            <code>source | extend Severity = case(level=="ERROR","High",...)</code>
                        </div>
                    </div>
                    <div class="flow-arrow">↓</div>

                    <div class="flow-step">
                        <div class="flow-step-number">5</div>
                        <div>
                            <strong>Custom Table</strong><br>
                            Data stored in Custom_AppLogs_CL<br>
                            <code>Query directly or create ASIM parser</code>
                        </div>
                    </div>

                    <h3>Complete Implementation</h3>

                    <div class="code-block">
                        <div class="code-header">
                            <span class="code-lang">JSON</span>
                            <span class="code-title">1. Create Custom Table Schema</span>
                        </div>
                        <pre><code>// Via Azure Portal: Log Analytics Workspace > Tables > Create > Custom Log (DCR-based)
// Or via API:
{
  "properties": {
    "schema": {
      "name": "AppLogs_CL",
      "columns": [
        {"name": "TimeGenerated", "type": "datetime"},
        {"name": "Level", "type": "string"},
        {"name": "Message", "type": "string"},
        {"name": "UserId", "type": "string"},
        {"name": "RequestId", "type": "string"},
        {"name": "SourceIP", "type": "string"},
        {"name": "Duration", "type": "int"},
        {"name": "Severity", "type": "string"}
      ]
    }
  }
}</code></pre>
                    </div>

                    <div class="code-block">
                        <div class="code-header">
                            <span class="code-lang">JSON</span>
                            <span class="code-title">2. Create DCR with Stream Declaration</span>
                        </div>
                        <pre><code>{
  "location": "eastus",
  "properties": {
    "dataCollectionEndpointId": "/subscriptions/.../dataCollectionEndpoints/dce-applogs",
    "streamDeclarations": {
      "Custom-AppLogs_CL": {
        "columns": [
          {"name": "TimeGenerated", "type": "datetime"},
          {"name": "RawData", "type": "string"},
          {"name": "level", "type": "string"},
          {"name": "message", "type": "string"},
          {"name": "user_id", "type": "string"},
          {"name": "request_id", "type": "string"},
          {"name": "source_ip", "type": "string"},
          {"name": "duration_ms", "type": "int"}
        ]
      }
    },
    "destinations": {
      "logAnalytics": [{
        "workspaceResourceId": "/subscriptions/.../workspaces/sentinel-ws",
        "name": "SentinelDestination"
      }]
    },
    "dataFlows": [{
      "streams": ["Custom-AppLogs_CL"],
      "destinations": ["SentinelDestination"],
      "transformKql": "source | extend TimeGenerated = todatetime(TimeGenerated), Level = level, Message = message, UserId = user_id, RequestId = request_id, SourceIP = source_ip, Duration = duration_ms, Severity = case(level == 'ERROR', 'High', level == 'WARN', 'Medium', 'Low') | project-away RawData, level, message, user_id, request_id, source_ip, duration_ms",
      "outputStream": "Custom-AppLogs_CL"
    }]
  }
}</code></pre>
                    </div>

                    <div class="code-block">
                        <div class="code-header">
                            <span class="code-lang">Python</span>
                            <span class="code-title">3. Azure Function to Send Logs</span>
                        </div>
                        <pre><code>import azure.functions as func
import json
import requests
from azure.identity import DefaultAzureCredential
from datetime import datetime

DCE_URI = "https://dce-applogs-xxxx.eastus-1.ingest.monitor.azure.com"
DCR_IMMUTABLE_ID = "dcr-xxxxxxxxxxxxxxxx"
STREAM_NAME = "Custom-AppLogs_CL"

def main(mytimer: func.TimerRequest) -> None:
    # Get AAD token for Logs Ingestion API
    credential = DefaultAzureCredential()
    token = credential.get_token("https://monitor.azure.com/.default")
    
    # Read logs from source (example: blob storage)
    logs = read_logs_from_source()  # Your implementation
    
    # Format for ingestion
    formatted_logs = []
    for log in logs:
        formatted_logs.append({
            "TimeGenerated": log.get("timestamp", datetime.utcnow().isoformat()),
            "level": log.get("level", "INFO"),
            "message": log.get("message", ""),
            "user_id": log.get("user_id", ""),
            "request_id": log.get("request_id", ""),
            "source_ip": log.get("source_ip", ""),
            "duration_ms": log.get("duration_ms", 0)
        })
    
    # Send to Logs Ingestion API
    url = f"{DCE_URI}/dataCollectionRules/{DCR_IMMUTABLE_ID}/streams/{STREAM_NAME}?api-version=2023-01-01"
    headers = {
        "Authorization": f"Bearer {token.token}",
        "Content-Type": "application/json"
    }
    
    # Batch in chunks of 1MB max
    response = requests.post(url, headers=headers, json=formatted_logs)
    
    if response.status_code == 204:
        print(f"Successfully sent {len(formatted_logs)} logs")
    else:
        raise Exception(f"Failed: {response.status_code} - {response.text}")</code></pre>
                    </div>
                </section>

                <!-- Flow 5: Azure Diagnostic Logs -->
                <section class="content-section">
                    <h2><i class="fab fa-microsoft"></i> Flow 5: Azure Service Diagnostic Logs</h2>
                    
                    <div class="log-source-card">
                        <h4>Source: Azure Key Vault / Storage / App Service</h4>
                        <p><strong>Target Table:</strong> AzureDiagnostics or Resource-specific</p>
                        <p><strong>Parsing:</strong> Built-in Azure parsing</p>
                        <p><strong>Method:</strong> Diagnostic Settings</p>
                    </div>

                    <h3>Two Destination Modes</h3>

                    <table class="styled-table">
                        <tr>
                            <th>Mode</th>
                            <th>Table</th>
                            <th>Schema</th>
                            <th>When to Use</th>
                        </tr>
                        <tr>
                            <td>Azure Diagnostics</td>
                            <td>AzureDiagnostics</td>
                            <td>Single table, all resources</td>
                            <td>Legacy, simple queries across types</td>
                        </tr>
                        <tr>
                            <td>Resource-specific</td>
                            <td>KeyVaultAuditEvent, StorageBlobLogs, etc.</td>
                            <td>Dedicated table per type</td>
                            <td>Recommended - better schema, lower cost</td>
                        </tr>
                    </table>

                    <div class="code-block">
                        <div class="code-header">
                            <span class="code-lang">Azure CLI</span>
                            <span class="code-title">Configure Diagnostic Settings</span>
                        </div>
                        <pre><code># Resource-specific mode (recommended)
az monitor diagnostic-settings create \
  --name "sentinel-diagnostics" \
  --resource "/subscriptions/xxx/resourceGroups/rg/providers/Microsoft.KeyVault/vaults/myvault" \
  --workspace "/subscriptions/xxx/resourceGroups/rg/providers/Microsoft.OperationalInsights/workspaces/sentinel-ws" \
  --export-to-resource-specific true \
  --logs '[{"category": "AuditEvent", "enabled": true}]'

# Query resource-specific table
# KeyVaultAuditEvent
# | where OperationName == "SecretGet"
# | project TimeGenerated, Identity, OperationName, ResultType</code></pre>
                    </div>
                </section>

                <!-- Parsing Decision Matrix -->
                <section class="content-section">
                    <h2><i class="fas fa-table"></i> Parsing Decision Matrix</h2>

                    <table class="styled-table">
                        <thead>
                            <tr>
                                <th>Log Source</th>
                                <th>Collection Method</th>
                                <th>Parser Type</th>
                                <th>Target Table</th>
                                <th>Normalization</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>Windows Security</td>
                                <td>AMA + DCR</td>
                                <td>Built-in</td>
                                <td>SecurityEvent</td>
                                <td>_Im_Authentication</td>
                            </tr>
                            <tr>
                                <td>Linux Syslog</td>
                                <td>AMA + DCR</td>
                                <td>Built-in</td>
                                <td>Syslog</td>
                                <td>_Im_Authentication</td>
                            </tr>
                            <tr>
                                <td>CEF Devices</td>
                                <td>AMA + Forwarder</td>
                                <td>CEF Parser</td>
                                <td>CommonSecurityLog</td>
                                <td>_Im_NetworkSession</td>
                            </tr>
                            <tr>
                                <td>Azure AD</td>
                                <td>Diagnostic Settings</td>
                                <td>Built-in</td>
                                <td>SigninLogs, AuditLogs</td>
                                <td>_Im_Authentication</td>
                            </tr>
                            <tr>
                                <td>Microsoft 365</td>
                                <td>M365 Connector</td>
                                <td>Built-in</td>
                                <td>OfficeActivity</td>
                                <td>_Im_WebSession</td>
                            </tr>
                            <tr>
                                <td>AWS CloudTrail</td>
                                <td>S3 Connector/Function</td>
                                <td>Built-in</td>
                                <td>AWSCloudTrail</td>
                                <td>_Im_AuditEvent</td>
                            </tr>
                            <tr>
                                <td>Custom App</td>
                                <td>Logs Ingestion API</td>
                                <td>DCR Transform</td>
                                <td>Custom_CL</td>
                                <td>Create custom parser</td>
                            </tr>
                        </tbody>
                    </table>
                </section>

                <!-- Interview Section -->
                <section class="content-section interview-section" style="background: linear-gradient(135deg, rgba(0,120,212,0.1), rgba(255,107,0,0.1)); border-radius: 12px; padding: 2rem;">
                    <h2><i class="fas fa-user-tie"></i> Interview Preparation</h2>

                    <div class="interview-box">
                        <div class="interview-question">
                            <i class="fas fa-question-circle"></i>
                            <span>Walk me through how a Windows Security event gets from a server to Sentinel.</span>
                        </div>
                        <div class="interview-answer">
                            <p>I'll trace the complete journey:</p>
                            <p><strong>1. Event Generation:</strong> Windows generates a Security event - say EventID 4625 (failed logon). It's written to the Security event log (Security.evtx) on the local disk.</p>
                            <p><strong>2. AMA Collection:</strong> The Azure Monitor Agent is running on the server. It has a DCRA linking it to a DCR that defines which events to collect via XPath queries. The agent continuously reads matching events from the event log.</p>
                            <p><strong>3. Filtering at Source:</strong> The DCR's XPath query acts as the first filter - only events matching the query are collected. This happens on the agent side, so unwanted events never leave the server.</p>
                            <p><strong>4. DCR Transformation:</strong> If the DCR has a transformKql, it's applied as data flows through. This can filter rows (like removing machine account logons), remove columns (to reduce cost), or add computed fields.</p>
                            <p><strong>5. Network Transfer:</strong> The agent batches events and sends them to Azure over HTTPS. For Azure VMs this is direct; for on-prem servers, it goes through Azure Arc.</p>
                            <p><strong>6. Table Storage:</strong> Data lands in the SecurityEvent table in Log Analytics workspace with all the parsed fields - EventID, Account, Computer, LogonType, etc. This is where Sentinel can query it.</p>
                            <p><strong>7. Analytics Processing:</strong> Scheduled analytics rules run KQL queries against SecurityEvent. If conditions match, an alert is created, which can trigger automation rules and playbooks.</p>
                            <p>The key insight is that there are multiple filtering opportunities - XPath on the agent, transformKql in the DCR, and KQL in analytics rules - each serving different purposes.</p>
                        </div>
                    </div>

                    <div class="interview-box">
                        <div class="interview-question">
                            <i class="fas fa-question-circle"></i>
                            <span>How would you onboard a new firewall vendor that sends CEF logs to Sentinel?</span>
                        </div>
                        <div class="interview-answer">
                            <p>I'd follow this process:</p>
                            <p><strong>1. Understand the source:</strong> First, I'd review the vendor documentation to confirm they support CEF format and understand their log categories (traffic, threat, system, etc.).</p>
                            <p><strong>2. Set up forwarder VM:</strong> Deploy a Linux VM in Azure (or Arc-enable an on-prem VM). Install AMA via Azure Portal or Azure Policy. Configure rsyslog to receive syslog on UDP/TCP 514 and forward CEF messages to the AMA socket.</p>
                            <p><strong>3. Create DCR:</strong> In Sentinel, use the "Common Event Format (CEF) via AMA" data connector. Create a DCR that specifies CEF data source with appropriate facilities. Associate the DCR with the forwarder VM.</p>
                            <p><strong>4. Configure the firewall:</strong> Point the firewall's syslog export to the forwarder VM's IP on port 514. Set the format to CEF if it's optional.</p>
                            <p><strong>5. Verify ingestion:</strong> Query CommonSecurityLog for the new DeviceVendor. Check that fields are parsing correctly - SourceIP, DestinationIP, DeviceAction should all be populated.</p>
                            <p><strong>6. Install Content Hub solution:</strong> If there's a vendor-specific solution in Content Hub, install it for analytics rules, workbooks, and hunting queries tailored to that vendor.</p>
                            <p><strong>7. Create or verify ASIM parser:</strong> Check if the vendor's CEF logs work with the ASIM NetworkSession parser. If custom fields need mapping, create a vendor-specific parser.</p>
                            <p>The main gotcha is ensuring the firewall is actually sending valid CEF - some vendors have quirks in their CEF implementation that require rsyslog preprocessing.</p>
                        </div>
                    </div>
                </section>

            </main>
            
            <footer class="content-footer">
                <div class="footer-content">
                    <p>Nik's SIEM - End-to-End Parsing Flows</p>
                    <p>Personal Reference</p>
                </div>
            </footer>
        </div>
    </div>
    
    <script src="../assets/js/main.js"></script>
</body>
</html>
