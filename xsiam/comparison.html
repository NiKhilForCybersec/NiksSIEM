<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>XSIAM vs Sentinel vs Splunk - Complete Technical Comparison | XSIAM</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="../assets/css/main.css">
</head>
<body>
    <div class="app-container">
        
    <!-- Sidebar -->
    <aside class="sidebar" id="sidebar">
        <div class="sidebar-header">
            <a href="../index.html" class="sidebar-brand">
                <i class="fas fa-shield-alt"></i>
                <span>Nik's SIEM</span>
            </a>
            <button class="sidebar-toggle" onclick="toggleSidebar()" title="Collapse sidebar">
                <i class="fas fa-chevron-left"></i>
            </button>
        </div>
        
        <div class="sidebar-content">
            <!-- Platforms Section -->
            <div class="sidebar-section">
                <div class="sidebar-section-title">Platforms</div>
                <ul class="sidebar-nav">
                    <li class="sidebar-nav-item">
                        <a href="../xsiam/index.html" class="sidebar-nav-link active" data-platform="xsiam">
                            <span class="platform-dot"></span>
                            <span>XSIAM</span>
                        </a>
                    </li>
                    <li class="sidebar-nav-item">
                        <a href="../splunk/index.html" class="sidebar-nav-link" data-platform="splunk">
                            <span class="platform-dot"></span>
                            <span>Splunk</span>
                        </a>
                    </li>
                    <li class="sidebar-nav-item">
                        <a href="../sentinel/index.html" class="sidebar-nav-link" data-platform="sentinel">
                            <span class="platform-dot"></span>
                            <span>Sentinel</span>
                        </a>
                    </li>
                    <li class="sidebar-nav-item">
                        <a href="../crowdstrike/index.html" class="sidebar-nav-link" data-platform="crowdstrike">
                            <span class="platform-dot"></span>
                            <span>CrowdStrike</span>
                        </a>
                    </li>
                    <li class="sidebar-nav-item">
                        <a href="../cortex/index.html" class="sidebar-nav-link" data-platform="cortex">
                            <span class="platform-dot"></span>
                            <span>Cortex XDR</span>
                        </a>
                    </li>
                    <li class="sidebar-nav-item">
                        <a href="../mde/index.html" class="sidebar-nav-link" data-platform="mde">
                            <span class="platform-dot"></span>
                            <span>Defender for Endpoint</span>
                        </a>
                    </li>
                    <li class="sidebar-nav-item">
                        <a href="../operations/index.html" class="sidebar-nav-link" data-platform="operations">
                            <span class="platform-dot"></span>
                            <span>SOC Operations</span>
                        </a>
                    </li>
                </ul>
            </div>

            <div class="sidebar-divider"></div>
            
            <!-- Current Platform Pages -->
            <div class="sidebar-section">
                <div class="sidebar-section-title">XSIAM Pages</div>
                <ul class="sidebar-nav">
                    <li class="sidebar-nav-item">
                        <a href="agents.html" class="sidebar-nav-link">
                            <i class="fas fa-microchip"></i>
                            <span>Agents</span>
                        </a>
                    </li>
                    <li class="sidebar-nav-item">
                        <a href="alert-management.html" class="sidebar-nav-link">
                            <i class="fas fa-bell"></i>
                            <span>Alert Management</span>
                        </a>
                    </li>
                    <li class="sidebar-nav-item">
                        <a href="architecture.html" class="sidebar-nav-link">
                            <i class="fas fa-sitemap"></i>
                            <span>Architecture</span>
                        </a>
                    </li>
                    <li class="sidebar-nav-item">
                        <a href="broker-vm.html" class="sidebar-nav-link">
                            <i class="fas fa-file-alt"></i>
                            <span>Broker Vm</span>
                        </a>
                    </li>
                    <li class="sidebar-nav-item">
                        <a href="comparison.html" class="sidebar-nav-link active">
                            <i class="fas fa-file-alt"></i>
                            <span>Comparison</span>
                        </a>
                    </li>
                    <li class="sidebar-nav-item">
                        <a href="correlation-rules.html" class="sidebar-nav-link">
                            <i class="fas fa-project-diagram"></i>
                            <span>Correlation Rules</span>
                        </a>
                    </li>
                    <li class="sidebar-nav-item">
                        <a href="custom-log-onboarding.html" class="sidebar-nav-link">
                            <i class="fas fa-download"></i>
                            <span>Custom Log Onboarding</span>
                        </a>
                    </li>
                    <li class="sidebar-nav-item">
                        <a href="dashboards.html" class="sidebar-nav-link">
                            <i class="fas fa-tachometer-alt"></i>
                            <span>Dashboards</span>
                        </a>
                    </li>
                    <li class="sidebar-nav-item">
                        <a href="data-ingestion.html" class="sidebar-nav-link">
                            <i class="fas fa-database"></i>
                            <span>Data Ingestion</span>
                        </a>
                    </li>
                    <li class="sidebar-nav-item">
                        <a href="enterprise-soc.html" class="sidebar-nav-link">
                            <i class="fas fa-building"></i>
                            <span>Enterprise Soc</span>
                        </a>
                    </li>
                    <li class="sidebar-nav-item">
                        <a href="index.html" class="sidebar-nav-link">
                            <i class="fas fa-home"></i>
                            <span>Overview</span>
                        </a>
                    </li>
                    <li class="sidebar-nav-item">
                        <a href="marketplace.html" class="sidebar-nav-link">
                            <i class="fas fa-file-alt"></i>
                            <span>Marketplace</span>
                        </a>
                    </li>
                    <li class="sidebar-nav-item">
                        <a href="parsing-flows.html" class="sidebar-nav-link">
                            <i class="fas fa-file-alt"></i>
                            <span>Parsing Flows</span>
                        </a>
                    </li>
                    <li class="sidebar-nav-item">
                        <a href="recon-asm.html" class="sidebar-nav-link">
                            <i class="fas fa-file-alt"></i>
                            <span>Recon Asm</span>
                        </a>
                    </li>
                    <li class="sidebar-nav-item">
                        <a href="retention-tiers.html" class="sidebar-nav-link">
                            <i class="fas fa-file-alt"></i>
                            <span>Retention Tiers</span>
                        </a>
                    </li>
                    <li class="sidebar-nav-item">
                        <a href="threat-intel.html" class="sidebar-nav-link">
                            <i class="fas fa-crosshairs"></i>
                            <span>Threat Intel</span>
                        </a>
                    </li>
                    <li class="sidebar-nav-item">
                        <a href="xdr-overview.html" class="sidebar-nav-link">
                            <i class="fas fa-home"></i>
                            <span>Xdr Overview</span>
                        </a>
                    </li>
                    <li class="sidebar-nav-item">
                        <a href="xql-advanced.html" class="sidebar-nav-link">
                            <i class="fas fa-terminal"></i>
                            <span>Xql Advanced</span>
                        </a>
                    </li>
                    <li class="sidebar-nav-item">
                        <a href="xql-fundamentals.html" class="sidebar-nav-link">
                            <i class="fas fa-code"></i>
                            <span>Xql Fundamentals</span>
                        </a>
                    </li>
                    <li class="sidebar-nav-item">
                        <a href="xsoar-automation.html" class="sidebar-nav-link">
                            <i class="fas fa-robot"></i>
                            <span>Xsoar Automation</span>
                        </a>
                    </li>
                </ul>
            </div>
        </div>
    </aside>
    
    <!-- Sidebar Overlay (for mobile) -->
    <div class="sidebar-overlay" id="sidebarOverlay" onclick="toggleSidebar()"></div>

        
        <!-- Main Content Wrapper -->
        <div class="main-wrapper" id="mainWrapper">
            <button class="mobile-toggle" onclick="toggleSidebar()" title="Open menu">
                <i class="fas fa-bars"></i>
            </button>
            
            <main class="main-content">
                <div class="breadcrumb">
                    <a href="../index.html">Home</a>
                    <span class="separator">/</span>
                    <a href="index.html">XSIAM</a>
                    <span class="separator">/</span>
                    <span class="current">Comparison</span>
                </div>

                <div class="page-header">
                    <span >COMPLETE TECHNICAL REFERENCE</span>
                    <h1><i class="fas fa-balance-scale"></i> XSIAM vs Sentinel vs Splunk</h1>
                    <p class="lead">Complete technical comparison covering ingestion, parsing, normalization, deployment, and automation with real-world examples</p>
                </div>
                <!-- Table of Contents -->
                <section class="content-section">
                    <h2><i class="fas fa-list"></i> What This Guide Covers</h2>
                    <div class="info-box">
                        <ul style="columns: 2; column-gap: 2rem;">
                            <li><a href="#ingestion">Data Ingestion Methods</a></li>
                            <li><a href="#parsing">Parsing & Field Extraction</a></li>
                            <li><a href="#normalization">Normalization (XDM/ASIM/CIM)</a></li>
                            <li><a href="#deployment">Deployment Architecture</a></li>
                            <li><a href="#builtin-parsers">Built-in vs Custom Parsers</a></li>
                            <li><a href="#examples">Real-World Examples</a></li>
                            <li><a href="#automation">Automation & SOAR</a></li>
                            <li><a href="#interview">Interview Preparation</a></li>
                        </ul>
                    </div>
                </section>
                <!-- Section 1: Data Ingestion Methods -->
                <section class="content-section" id="ingestion">
                    <h2><i class="fas fa-database"></i> Data Ingestion Methods - Complete Breakdown</h2>
                    <p>Each platform has fundamentally different approaches to getting data in. Understanding these is critical for architecture decisions and troubleshooting.</p>
                    <table class="comparison-table">
                        <thead>
                            <tr>
                                <th style="width: 18%;">Ingestion Method</th>
                                <th class="platform-header xsiam" style="width: 27%;">Cortex XSIAM</th>
                                <th class="platform-header sentinel" style="width: 27%;">Microsoft Sentinel</th>
                                <th class="platform-header splunk" style="width: 27%;">Splunk</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr class="feature-category"><td colspan="4"><i class="fas fa-server"></i> AGENT-BASED COLLECTION</td></tr>
                            <tr>
                                <td><strong>Primary Agent</strong></td>
                                <td><strong>Cortex XDR Agent</strong><br>• Full EDR capabilities<br>• Process/file/network telemetry<br>• Native XDM normalization<br>• Windows, Linux, macOS</td>
                                <td><strong>Azure Monitor Agent (AMA)</strong><br>• Replaced MMA (deprecated Aug 2024)<br>• Requires Azure Arc for on-prem<br>• Configured via DCR<br>• Windows, Linux</td>
                                <td><strong>Universal Forwarder (UF)</strong><br>• Lightweight, no parsing<br>• File monitoring, WinEventLog<br>• Sends raw data to indexer<br>• Windows, Linux, macOS</td>
                            </tr>
                            <tr>
                                <td><strong>Agent Capabilities</strong></td>
                                <td>• EDR + Data Collection<br>• Response actions (isolate, kill)<br>• Local analysis<br>• Causality chain tracking</td>
                                <td>• Data collection only<br>• No EDR (requires MDE)<br>• XPath filtering<br>• DCR-controlled collection</td>
                                <td>• Data forwarding only<br>• No parsing (unless force_local)<br>• Load balancing to indexers<br>• Scripted inputs</td>
                            </tr>
                            <tr>
                                <td><strong>Collection Agent</strong></td>
                                <td><strong>XDR Collector</strong><br>• Filebeat-based<br>• File log collection<br>• Used for third-party logs</td>
                                <td><strong>AMA</strong><br>• Same agent for all collection<br>• Multi-homing supported<br>• DCE for custom logs</td>
                                <td><strong>Heavy Forwarder (HF)</strong><br>• Full Splunk instance<br>• Can parse/transform<br>• Run modular inputs</td>
                            </tr>
                            <tr class="feature-category"><td colspan="4"><i class="fas fa-network-wired"></i> NETWORK/SYSLOG COLLECTION</td></tr>
                            <tr>
                                <td><strong>Syslog Receiver</strong></td>
                                <td><strong>Broker VM</strong><br>• Syslog Collector applet<br>• TCP/UDP/TLS<br>• CEF/LEEF auto-parsing<br>• On-prem or cloud VM</td>
                                <td><strong>AMA on Linux VM</strong><br>• rsyslog/syslog-ng → AMA<br>• CEF via CommonSecurityLog<br>• DCR controls facility/severity<br>• Azure VM or Arc-enabled</td>
                                <td><strong>Heavy Forwarder</strong><br>• Syslog input (UDP/TCP)<br>• Can parse at HF<br>• Or forward raw to indexer</td>
                            </tr>
                            <tr>
                                <td><strong>CEF/LEEF Handling</strong></td>
                                <td>Built-in CEF/LEEF parser<br>Auto-extracts to key-value<br>Maps to XDM automatically</td>
                                <td>CEF → CommonSecurityLog table<br>Built-in parser<br>ASIM via ASimCommonSecurityLog</td>
                                <td>Splunk_TA_cef<br>CIM mapping via TA<br>Search-time extraction</td>
                            </tr>
                            <tr>
                                <td><strong>Syslog Config Example</strong></td>
                                <td><code>Broker VM → Syslog Collector<br>Port: 514 (UDP/TCP)<br>TLS: 6514</code></td>
                                <td><code>DCR: facilityNames: [auth]<br>logLevels: [Warning, Error]<br>streams: Microsoft-Syslog</code></td>
                                <td><code>[udp://514]<br>sourcetype = syslog<br>connection_host = dns</code></td>
                            </tr>
                            <tr class="feature-category"><td colspan="4"><i class="fas fa-cloud"></i> API/CLOUD COLLECTION</td></tr>
                            <tr>
                                <td><strong>API Polling</strong></td>
                                <td><strong>Data Sources (Integrations)</strong><br>• Built-in API connectors<br>• Office 365, AWS, Azure<br>• Configured in UI<br>• Marketplace content packs</td>
                                <td><strong>Azure Functions + Logic Apps</strong><br>• Custom function polls API<br>• Sends via Log Ingestion API<br>• Content Hub solutions<br>• Data Connector templates</td>
                                <td><strong>Modular Inputs / Add-ons</strong><br>• Python-based inputs<br>• Run on HF or SH<br>• Splunkbase TAs<br>• HTTP Event Collector (HEC)</td>
                            </tr>
                            <tr>
                                <td><strong>HTTP/REST Ingestion</strong></td>
                                <td><strong>HTTP Log Collector</strong><br>• REST API endpoint<br>• JSON payload<br>• Authentication via API key</td>
                                <td><strong>Logs Ingestion API</strong><br>• POST to DCE endpoint<br>• DCR transforms data<br>• Custom or standard tables<br>• Requires AAD auth</td>
                                <td><strong>HTTP Event Collector (HEC)</strong><br>• REST endpoint on indexer<br>• Token-based auth<br>• JSON events<br>• Acknowledgment support</td>
                            </tr>
                            <tr>
                                <td><strong>Cloud-to-Cloud</strong></td>
                                <td>• AWS S3 polling<br>• Azure Event Hub<br>• GCP Pub/Sub<br>• Office 365 Management API</td>
                                <td>• Native Azure integration<br>• AWS S3 via Function<br>• Event Hub (best for Azure)<br>• Diagnostic Settings direct</td>
                                <td>• Splunk Add-on for AWS<br>• Splunk Add-on for Azure<br>• GCP Add-on<br>• Kinesis Firehose</td>
                            </tr>
                            <tr class="feature-category"><td colspan="4"><i class="fas fa-filter"></i> DATA FILTERING AT INGESTION</td></tr>
                            <tr>
                                <td><strong>Pre-Ingest Filtering</strong></td>
                                <td><strong>Parsing Rules</strong><br>• Drop unnecessary logs<br>• Filter at Broker VM<br>• Dataset rules</td>
                                <td><strong>DCR Transformations</strong><br>• KQL in transformKql<br>• project-away columns<br>• where clause filtering<br>• Runs before storage</td>
                                <td><strong>props.conf + transforms.conf</strong><br>• TRANSFORMS-null on HF<br>• Route to nullQueue<br>• SEDCMD for masking</td>
                            </tr>
                            <tr>
                                <td><strong>Cost Optimization</strong></td>
                                <td>Filter at Broker VM<br>Only ingest needed data<br>Dataset storage tiers</td>
                                <td>DCR filtering critical<br>Basic Logs tier (cheaper)<br>Auxiliary Logs (new 2025)<br>30 days interactive</td>
                                <td>Filter at HF layer<br>Summary indexes<br>Data model acceleration</td>
                            </tr>
                        </tbody>
                    </table>
                    <!-- Ingestion Architecture Diagrams -->
                    <h3>Data Flow Architecture</h3>
                    <div class="deep-dive">
                        <h4 style="color: #ff6b00;"><i class="fas fa-fire"></i> XSIAM Data Flow</h4>
                        <div class="architecture-diagram">
<p style="color: #8b949e;">[Diagram - see related pages for visual representation]</p>
                        </div>
                        <p><strong>Key Components:</strong></p>
                        <ul>
                            <li><strong>Cortex XDR Agent:</strong> Native endpoint telemetry, already normalized to XDM</li>
                            <li><strong>Broker VM:</strong> On-prem VM for syslog/CEF collection, runs Syslog Collector applet</li>
                            <li><strong>Parsing Rules:</strong> Extract fields from raw logs, bound to vendor/product</li>
                            <li><strong>Data Model Rules:</strong> Map extracted fields to XDM schema for correlation</li>
                        </ul>
                    </div>
                    <div class="deep-dive">
                        <h4 style="color: #0078d4;"><i class="fas fa-shield-alt"></i> Microsoft Sentinel Data Flow</h4>
                        <div class="architecture-diagram">
<p style="color: #8b949e;">[Diagram - see related pages for visual representation]</p>
                        </div>
                        <p><strong>Key Components:</strong></p>
                        <ul>
                            <li><strong>AMA (Azure Monitor Agent):</strong> Modern agent replacing legacy MMA, requires Azure Arc for on-prem</li>
                            <li><strong>DCR (Data Collection Rule):</strong> Defines WHAT to collect, HOW to transform, WHERE to send</li>
                            <li><strong>DCE (Data Collection Endpoint):</strong> HTTP endpoint for Logs Ingestion API and custom data</li>
                            <li><strong>DCRA (DCR Association):</strong> Links a DCR to specific VMs/resources</li>
                            <li><strong>Workspace Transformation DCR:</strong> Applies to data not using standard DCR (legacy connectors)</li>
                        </ul>
                    </div>
                    <div class="deep-dive">
                        <h4 style="color: #65a637;"><i class="fas fa-search"></i> Splunk Data Flow</h4>
                        <div class="architecture-diagram">
<p style="color: #8b949e;">[Diagram - see related pages for visual representation]</p>
                        </div>
                        <p><strong>Key Components:</strong></p>
                        <ul>
                            <li><strong>Universal Forwarder (UF):</strong> Lightweight agent, forwards raw data, minimal processing</li>
                            <li><strong>Heavy Forwarder (HF):</strong> Full Splunk, can parse, route, mask, run modular inputs</li>
                            <li><strong>Deployment Server:</strong> Centralized management - pushes configs to forwarders</li>
                            <li><strong>props.conf:</strong> Field extraction, line breaking, timestamp parsing</li>
                            <li><strong>transforms.conf:</strong> Field transforms, routing, masking</li>
                        </ul>
                    </div>
                </section>
                <!-- Section 2: Parsing Deep Dive -->
                <section class="content-section" id="parsing">
                    <h2><i class="fas fa-cut"></i> Parsing & Field Extraction - How Each Platform Does It</h2>
                    <table class="comparison-table">
                        <thead>
                            <tr>
                                <th style="width: 18%;">Parsing Aspect</th>
                                <th class="platform-header xsiam">XSIAM</th>
                                <th class="platform-header sentinel">Sentinel</th>
                                <th class="platform-header splunk">Splunk</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr class="feature-category"><td colspan="4"><i class="fas fa-clock"></i> WHEN PARSING HAPPENS</td></tr>
                            <tr>
                                <td><strong>Parsing Time</strong></td>
                                <td><strong>Ingest-time</strong><br>Parsing rules run as data arrives<br>Fields stored in dataset</td>
                                <td><strong>Both options:</strong><br>• Ingest-time: DCR transforms<br>• Query-time: ASIM parsers</td>
                                <td><strong>Both options:</strong><br>• Index-time: props/transforms<br>• Search-time: rex, props</td>
                            </tr>
                            <tr>
                                <td><strong>Default Behavior</strong></td>
                                <td>Auto-parse structured formats<br>(CEF, LEEF, JSON, Syslog)</td>
                                <td>Built-in connectors parse<br>Custom needs DCR config</td>
                                <td>Basic parsing by sourcetype<br>TAs add field extraction</td>
                            </tr>
                            <tr class="feature-category"><td colspan="4"><i class="fas fa-code"></i> PARSING SYNTAX</td></tr>
                            <tr>
                                <td><strong>Field Extraction</strong></td>
                                <td><strong>XQL in Parsing Rules</strong><br><code>alter field = regextract(_raw_log, "pattern")</code></td>
                                <td><strong>KQL in DCR</strong><br><code>| extend field = extract("pattern", 1, RawData)</code></td>
                                <td><strong>props.conf EXTRACT</strong><br><code>EXTRACT-field = (?&lt;field&gt;\d+)</code></td>
                            </tr>
                            <tr>
                                <td><strong>Timestamp Parsing</strong></td>
                                <td>Parsing rule populates _time<br>Multiple format support</td>
                                <td>TimeGenerated from source<br>or ingestion time</td>
                                <td>TIME_FORMAT in props.conf<br>TIME_PREFIX to locate</td>
                            </tr>
                            <tr>
                                <td><strong>Event Breaking</strong></td>
                                <td>Handled by collector<br>JSON auto-detected</td>
                                <td>Line-based by default<br>Multi-line via DCR</td>
                                <td>LINE_BREAKER in props.conf<br>SHOULD_LINEMERGE</td>
                            </tr>
                        </tbody>
                    </table>
                    <h3>Parsing Examples - Same Log, Three Platforms</h3>
                    <div class="example-scenario">
                        <h4>Scenario: Parse Palo Alto Firewall Traffic Log</h4>
                        <p><strong>Raw Log:</strong></p>
                        <pre><code>Jan 15 10:23:45 fw01 1,2024/01/15 10:23:45,001234567890,TRAFFIC,end,2560,2024/01/15 10:23:45,192.168.1.100,203.0.113.50,0.0.0.0,0.0.0.0,allow-outbound,,,web-browsing,vsys1,trust,untrust,ethernet1/2,ethernet1/1,Log-Forwarding,2024/01/15 10:23:45,12345,1,54321,443,0,0,0x400000,tcp,allow,1500,500,1000,10,2024/01/15 10:23:40,5,any,0</code></pre>
                    </div>
                    <div class="code-block">
                        <div class="code-header">
                            <span class="code-lang" >XSIAM</span>
                            <span class="code-title">Parsing Rule + Data Model Rule</span>
                        </div>
                        <pre><code>// XSIAM Parsing Rule (extracts fields from raw)
[INGEST:VENDOR_PANW_PRODUCT_PAN_FIREWALL]
filter _raw_log ~= "TRAFFIC"
| alter 
    src_ip = arrayindex(regextract(_raw_log, ",(\d+\.\d+\.\d+\.\d+),"), 0),
    dst_ip = arrayindex(regextract(_raw_log, ",\d+\.\d+\.\d+\.\d+,(\d+\.\d+\.\d+\.\d+),"), 0),
    action = arrayindex(regextract(_raw_log, ",(allow|deny),"), 0),
    bytes_sent = to_integer(arrayindex(regextract(_raw_log, ",(\d+),\d+,\d+,\d+,"), 0)),
    app = arrayindex(regextract(_raw_log, ",([^,]+),vsys"), 0);
// Data Model Rule (maps to XDM)
[MODEL:VENDOR_PANW_PRODUCT_PAN_FIREWALL]
call PANW_FIREWALL_TRAFFIC_FIELDS
| alter
    xdm.source.ipv4 = src_ip,
    xdm.target.ipv4 = dst_ip,
    xdm.event.outcome = if(action = "allow", XDM_CONST.OUTCOME_SUCCESS, XDM_CONST.OUTCOME_FAILED),
    xdm.network.application_protocol = app,
    xdm.source.sent_bytes = bytes_sent;</code></pre>
                    </div>
                    <div class="code-block">
                        <div class="code-header">
                            <span class="code-lang" >KQL</span>
                            <span class="code-title">DCR Transformation + ASIM Parser</span>
                        </div>
                        <pre><code>// DCR Transformation (ingest-time)
source
| extend 
    SrcIpAddr = extract(@",(\d+\.\d+\.\d+\.\d+),", 1, RawData),
    DstIpAddr = extract(@",\d+\.\d+\.\d+\.\d+,(\d+\.\d+\.\d+\.\d+),", 1, RawData),
    DvcAction = extract(@",(allow|deny),", 1, RawData),
    SrcBytes = toint(extract(@",(\d+),\d+,\d+,\d+,", 1, RawData)),
    NetworkApplicationProtocol = extract(@",([^,]+),vsys", 1, RawData)
| project-away RawData
// ASIM Network Session Parser (query-time normalization)
_Im_NetworkSession(starttime=ago(1h), srcipaddr_has_any_prefix=dynamic(['192.168.']))
| where EventProduct == "PAN-OS"
| project TimeGenerated, SrcIpAddr, DstIpAddr, DvcAction, SrcBytes</code></pre>
                    </div>
                    <div class="code-block">
                        <div class="code-header">
                            <span class="code-lang" >Splunk</span>
                            <span class="code-title">props.conf + transforms.conf</span>
                        </div>
                        <pre><code># props.conf (on Indexer or HF)
[pan:traffic]
TIME_FORMAT = %Y/%m/%d %H:%M:%S
TIME_PREFIX = ^\w+\s+\d+\s+\d+:\d+:\d+\s+\S+\s+\d+,
MAX_TIMESTAMP_LOOKAHEAD = 30
SHOULD_LINEMERGE = false
TRANSFORMS-pan = pan_traffic_fields
# transforms.conf
[pan_traffic_fields]
REGEX = ,(?P<src_ip>\d+\.\d+\.\d+\.\d+),(?P<dst_ip>\d+\.\d+\.\d+\.\d+),.*?,(?P<action>allow|deny),.*?,(?P<app>[^,]+),vsys
FORMAT = src_ip::$1 dst_ip::$2 action::$3 app::$4
# CIM Mapping (eventtypes.conf + tags.conf)
[eventtype=pan_traffic]
search = sourcetype="pan:traffic"
[pan_traffic]
network = enabled
communicate = enabled
# Field aliases for CIM (props.conf)
FIELDALIAS-src = src_ip AS src
FIELDALIAS-dest = dst_ip AS dest</code></pre>
                    </div>
                </section>
                <!-- Section 3: Normalization Deep Dive -->
                <section class="content-section" id="normalization">
                    <h2><i class="fas fa-sitemap"></i> Normalization Frameworks - XDM vs ASIM vs CIM</h2>
                    <p>Normalization allows you to write a single query that works across all data sources. Each platform has its own schema:</p>
                    <table class="comparison-table">
                        <thead>
                            <tr>
                                <th style="width: 20%;">Aspect</th>
                                <th class="platform-header xsiam">XDM (XSIAM)</th>
                                <th class="platform-header sentinel">ASIM (Sentinel)</th>
                                <th class="platform-header splunk">CIM (Splunk)</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>Full Name</strong></td>
                                <td>eXtensible Data Model</td>
                                <td>Advanced Security Information Model</td>
                                <td>Common Information Model</td>
                            </tr>
                            <tr>
                                <td><strong>Normalization Time</strong></td>
                                <td><strong>Ingest-time only</strong><br>Data stored normalized</td>
                                <td><strong>Both:</strong><br>• Ingest-time (DCR)<br>• Query-time (parsers)</td>
                                <td><strong>Search-time only</strong><br>Raw data preserved</td>
                            </tr>
                            <tr>
                                <td><strong>Schema Definition</strong></td>
                                <td>Palo Alto defined<br>~200 XDM fields</td>
                                <td>Microsoft defined<br>OCSF-aligned</td>
                                <td>Splunk defined<br>Data model per domain</td>
                            </tr>
                            <tr>
                                <td><strong>Flexibility</strong></td>
                                <td>Fixed schema<br>Custom fields allowed</td>
                                <td>Flexible - choose approach<br>Can keep raw + normalized</td>
                                <td>Most flexible<br>Raw always available</td>
                            </tr>
                        </tbody>
                    </table>
                    <h3>Schema Comparison - Network Session Example</h3>
                    <table class="comparison-table">
                        <thead>
                            <tr>
                                <th>Concept</th>
                                <th class="platform-header xsiam">XDM Field</th>
                                <th class="platform-header sentinel">ASIM Field</th>
                                <th class="platform-header splunk">CIM Field</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr><td>Source IP</td><td>xdm.source.ipv4</td><td>SrcIpAddr</td><td>src</td></tr>
                            <tr><td>Destination IP</td><td>xdm.target.ipv4</td><td>DstIpAddr</td><td>dest</td></tr>
                            <tr><td>Source Port</td><td>xdm.source.port</td><td>SrcPortNumber</td><td>src_port</td></tr>
                            <tr><td>Destination Port</td><td>xdm.target.port</td><td>DstPortNumber</td><td>dest_port</td></tr>
                            <tr><td>Protocol</td><td>xdm.network.ip_protocol</td><td>NetworkProtocol</td><td>protocol</td></tr>
                            <tr><td>Action</td><td>xdm.event.outcome</td><td>DvcAction</td><td>action</td></tr>
                            <tr><td>Bytes Sent</td><td>xdm.source.sent_bytes</td><td>SrcBytes</td><td>bytes_out</td></tr>
                            <tr><td>User</td><td>xdm.source.user.username</td><td>SrcUsername</td><td>user</td></tr>
                            <tr><td>Application</td><td>xdm.network.application_protocol</td><td>NetworkApplicationProtocol</td><td>app</td></tr>
                            <tr><td>Device Vendor</td><td>xdm.observer.vendor</td><td>EventVendor</td><td>vendor_product</td></tr>
                        </tbody>
                    </table>
                    <h3>Querying Normalized Data</h3>
                    <div class="code-block">
                        <div class="code-header">
                            <span class="code-lang" >XQL</span>
                            <span class="code-title">Query all firewall data via XDM</span>
                        </div>
                        <pre><code>// Works across Palo Alto, Fortinet, Cisco, Check Point - all normalized to XDM
datamodel
| filter xdm.event.type = ENUM.NETWORK
| filter xdm.event.outcome = XDM_CONST.OUTCOME_FAILED  // Blocked connections
| comp count() as blocked_count by xdm.source.ipv4, xdm.target.ipv4
| sort desc blocked_count
| limit 100</code></pre>
                    </div>
                    <div class="code-block">
                        <div class="code-header">
                            <span class="code-lang" >KQL</span>
                            <span class="code-title">Query all firewall data via ASIM</span>
                        </div>
                        <pre><code>// ASIM unifying parser - works across all onboarded firewalls
_Im_NetworkSession
| where DvcAction == "Deny"
| summarize BlockedCount = count() by SrcIpAddr, DstIpAddr
| sort by BlockedCount desc
| take 100
// Can also call source-specific parser for single vendor
_ASim_NetworkSession_PaloAltoNetworks
| where TimeGenerated > ago(1h)</code></pre>
                    </div>
                    <div class="code-block">
                        <div class="code-header">
                            <span class="code-lang" >SPL</span>
                            <span class="code-title">Query all firewall data via CIM</span>
                        </div>
                        <pre><code>// CIM-compliant search using data model
| tstats count as blocked_count from datamodel=Network_Traffic 
  where All_Traffic.action=blocked 
  by All_Traffic.src, All_Traffic.dest
| sort -blocked_count
| head 100
// Or using tag-based search
index=* tag=network tag=communicate action=blocked
| stats count by src, dest
| sort -count</code></pre>
                    </div>
                </section>
                <!-- Section 4: Deployment & Management -->
                <section class="content-section" id="deployment">
                    <h2><i class="fas fa-server"></i> Deployment & Configuration Management</h2>
                    <table class="comparison-table">
                        <thead>
                            <tr>
                                <th style="width: 20%;">Management Aspect</th>
                                <th class="platform-header xsiam">XSIAM</th>
                                <th class="platform-header sentinel">Sentinel</th>
                                <th class="platform-header splunk">Splunk</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr class="feature-category"><td colspan="4"><i class="fas fa-cogs"></i> CENTRALIZED MANAGEMENT</td></tr>
                            <tr>
                                <td><strong>Config Management</strong></td>
                                <td><strong>XSIAM Console</strong><br>• Cloud-based<br>• Agent policies<br>• Data source configs</td>
                                <td><strong>DCR + Azure Policy</strong><br>• DCR defines collection<br>• Azure Policy deploys<br>• ARM templates for IaC</td>
                                <td><strong>Deployment Server</strong><br>• Pushes apps to forwarders<br>• Server classes<br>• Centralized props/transforms</td>
                            </tr>
                            <tr>
                                <td><strong>Agent Deployment</strong></td>
                                <td>• XSIAM console packages<br>• SCCM/Intune integration<br>• Broker VM installation</td>
                                <td>• Azure Policy auto-install<br>• Azure Arc for on-prem<br>• DCR auto-associates</td>
                                <td>• Deployment server apps<br>• Ansible/Puppet<br>• SCCM packages</td>
                            </tr>
                            <tr>
                                <td><strong>Scale Management</strong></td>
                                <td>Cloud-native, auto-scales</td>
                                <td>Cloud-native, auto-scales<br>Workspace-level control</td>
                                <td>Indexer cluster<br>Search head cluster<br>Manual scaling</td>
                            </tr>
                            <tr class="feature-category"><td colspan="4"><i class="fas fa-file-code"></i> CONFIGURATION FILES</td></tr>
                            <tr>
                                <td><strong>Key Config Files</strong></td>
                                <td>• Parsing Rules (YAML)<br>• Data Model Rules (YAML)<br>• Correlation Rules (UI/YAML)</td>
                                <td>• DCR (JSON/ARM)<br>• Analytics Rules (JSON/YAML)<br>• Watchlists (CSV/JSON)</td>
                                <td>• inputs.conf<br>• props.conf<br>• transforms.conf<br>• outputs.conf<br>• serverclass.conf</td>
                            </tr>
                            <tr>
                                <td><strong>Where Configs Live</strong></td>
                                <td>Cloud platform<br>Marketplace content packs</td>
                                <td>Azure Resource Manager<br>Content Hub solutions</td>
                                <td>$SPLUNK_HOME/etc/apps/<br>Deployment apps</td>
                            </tr>
                        </tbody>
                    </table>
                    <h3>Configuration Examples</h3>
                    <div class="deep-dive">
                        <h4 style="color: #0078d4;">Sentinel: DCR Configuration (JSON)</h4>
                        <pre><code>{
  "properties": {
    "dataSources": {
      "windowsEventLogs": [{
        "name": "SecurityEvents",
        "streams": ["Microsoft-SecurityEvent"],
        "xPathQueries": [
          "Security!*[System[(EventID=4624 or EventID=4625 or EventID=4648)]]",
          "Security!*[System[(EventID=4720 or EventID=4722 or EventID=4723)]]"
        ]
      }],
      "syslog": [{
        "name": "AuthLogs",
        "streams": ["Microsoft-Syslog"],
        "facilityNames": ["auth", "authpriv"],
        "logLevels": ["Warning", "Error", "Critical", "Alert", "Emergency"]
      }]
    },
    "destinations": {
      "logAnalytics": [{
        "workspaceResourceId": "/subscriptions/.../workspaces/SentinelWorkspace",
        "name": "SecurityWorkspace"
      }]
    },
    "dataFlows": [{
      "streams": ["Microsoft-SecurityEvent", "Microsoft-Syslog"],
      "destinations": ["SecurityWorkspace"],
      "transformKql": "source | where EventID != 4688 or NewProcessName !contains 'svchost'"
    }]
  }
}</code></pre>
                        <p><strong>Key Points:</strong> DCR controls what events to collect (XPath), which facilities/severities (syslog), and transformations (KQL) before storage.</p>
                    </div>
                    <div class="deep-dive">
                        <h4 style="color: #65a637;">Splunk: Deployment Server Configuration</h4>
                        <pre><code># serverclass.conf (on Deployment Server)
[serverClass:Windows_Security]
whitelist.0 = *.corp.local
machineTypesFilter = windows-x64
[serverClass:Windows_Security:app:Splunk_TA_windows]
restartSplunkWeb = false
restartSplunkd = true
[serverClass:Linux_Servers]
whitelist.0 = linux-*
machineTypesFilter = linux-x64
[serverClass:Linux_Servers:app:Splunk_TA_nix]
# inputs.conf (in deployment app for Windows)
[WinEventLog://Security]
disabled = 0
index = wineventlog
evt_resolve_ad_obj = 1
checkpointInterval = 5
# props.conf (on Indexer - index-time parsing)
[WinEventLog:Security]
TIME_FORMAT = %m/%d/%Y %I:%M:%S %p
TZ = UTC
SHOULD_LINEMERGE = false
TRANSFORMS-setnull = setnull
# transforms.conf (on Indexer - drop EventCode 4688 with svchost)
[setnull]
REGEX = EventCode=4688.*NewProcessName.*svchost
DEST_KEY = queue
FORMAT = nullQueue</code></pre>
                        <p><strong>Key Points:</strong> Deployment Server pushes apps to forwarder classes. props.conf/transforms.conf on indexer handle parsing and filtering.</p>
                    </div>
                </section>
                <!-- Section 5: Built-in vs Custom Parsers -->
                <section class="content-section" id="builtin-parsers">
                    <h2><i class="fas fa-puzzle-piece"></i> Built-in vs Custom Parsers</h2>
                    <table class="comparison-table">
                        <thead>
                            <tr>
                                <th style="width: 18%;">Parser Type</th>
                                <th class="platform-header xsiam">XSIAM</th>
                                <th class="platform-header sentinel">Sentinel</th>
                                <th class="platform-header splunk">Splunk</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr class="feature-category"><td colspan="4"><i class="fas fa-box"></i> BUILT-IN PARSERS</td></tr>
                            <tr>
                                <td><strong>Where to Find</strong></td>
                                <td><strong>Marketplace</strong><br>800+ content packs<br>Auto-parsing for CEF/LEEF/JSON</td>
                                <td><strong>Content Hub</strong><br>300+ solutions<br>Built-in ASIM parsers</td>
                                <td><strong>Splunkbase</strong><br>2,500+ TAs<br>CIM-compliant add-ons</td>
                            </tr>
                            <tr>
                                <td><strong>Examples</strong></td>
                                <td>• Palo Alto NGFW<br>• CrowdStrike Falcon<br>• Okta<br>• AWS CloudTrail<br>• Microsoft O365</td>
                                <td>• Microsoft Defender<br>• Azure Firewall<br>• Palo Alto (via CEF)<br>• Cisco ASA<br>• AWS (via function)</td>
                                <td>• Splunk_TA_windows<br>• Splunk_TA_paloalto<br>• Splunk_TA_cisco<br>• TA-crowdstrike<br>• Splunk_TA_aws</td>
                            </tr>
                            <tr>
                                <td><strong>Installation</strong></td>
                                <td>Install from Marketplace<br>Auto-enables parsing rules</td>
                                <td>Install from Content Hub<br>Deploy data connector</td>
                                <td>Download from Splunkbase<br>Deploy via Deployment Server</td>
                            </tr>
                            <tr class="feature-category"><td colspan="4"><i class="fas fa-wrench"></i> CUSTOM PARSERS</td></tr>
                            <tr>
                                <td><strong>When Needed</strong></td>
                                <td>• Custom application logs<br>• Unsupported vendors<br>• Non-standard formats</td>
                                <td>• Custom applications<br>• Unsupported sources<br>• Special transformations</td>
                                <td>• Custom sourcetypes<br>• Vendor without TA<br>• Unique log formats</td>
                            </tr>
                            <tr>
                                <td><strong>Creation Method</strong></td>
                                <td><strong>Parsing Rule + Data Model Rule</strong><br>XQL-based extraction<br>Map to XDM schema</td>
                                <td><strong>DCR + Custom Parser</strong><br>KQL transformation<br>Custom table or ASIM</td>
                                <td><strong>props.conf + transforms.conf</strong><br>Regex extraction<br>Field aliases for CIM</td>
                            </tr>
                        </tbody>
                    </table>
                    <h3>Custom Parser Example - In-House Application Logs</h3>
                    <div class="example-scenario">
                        <h4>Scenario: Parse custom authentication log from in-house app</h4>
                        <p><strong>Raw Log Format:</strong></p>
                        <pre><code>2025-01-15T10:23:45.123Z|AUTH|SUCCESS|user=jsmith|src_ip=192.168.1.50|method=password|session_id=abc123
2025-01-15T10:23:46.456Z|AUTH|FAILED|user=badactor|src_ip=203.0.113.10|method=password|reason=invalid_password</code></pre>
                    </div>
                    <div class="code-block">
                        <div class="code-header">
                            <span class="code-lang" >XSIAM</span>
                            <span class="code-title">Custom Parsing Rule</span>
                        </div>
                        <pre><code>// Step 1: Create dataset for custom app (in data sources config)
// vendor=CUSTOM, product=MYAPP, format=Auto
// Step 2: Parsing Rule
[INGEST:VENDOR_CUSTOM_PRODUCT_MYAPP]
filter _raw_log ~= "\|AUTH\|"
| alter
    _time = parse_timestamp("%Y-%m-%dT%H:%M:%E*S%Ez", arrayindex(split(_raw_log, "|"), 0)),
    event_type = arrayindex(split(_raw_log, "|"), 1),
    outcome = arrayindex(split(_raw_log, "|"), 2),
    username = arrayindex(regextract(_raw_log, "user=([^\|]+)"), 0),
    source_ip = arrayindex(regextract(_raw_log, "src_ip=([^\|]+)"), 0),
    auth_method = arrayindex(regextract(_raw_log, "method=([^\|]+)"), 0),
    failure_reason = arrayindex(regextract(_raw_log, "reason=([^\|]+)"), 0);
// Step 3: Data Model Rule (map to XDM)
[MODEL:VENDOR_CUSTOM_PRODUCT_MYAPP]
filter event_type = "AUTH"
| alter
    xdm.event.type = ENUM.AUTHENTICATION,
    xdm.event.outcome = if(outcome = "SUCCESS", XDM_CONST.OUTCOME_SUCCESS, XDM_CONST.OUTCOME_FAILED),
    xdm.source.user.username = username,
    xdm.source.ipv4 = source_ip,
    xdm.auth.auth_method = auth_method,
    xdm.event.outcome_reason = failure_reason;</code></pre>
                    </div>
                    <div class="code-block">
                        <div class="code-header">
                            <span class="code-lang" >Sentinel</span>
                            <span class="code-title">DCR + Custom Table</span>
                        </div>
                        <pre><code>// Step 1: Create Custom Table (via Azure Portal or API)
// Table name: CustomApp_Auth_CL
// Step 2: DCR with Transformation
{
  "dataFlows": [{
    "streams": ["Custom-CustomApp_Auth_CL"],
    "destinations": ["SecurityWorkspace"],
    "transformKql": "source 
      | extend Parts = split(RawData, '|')
      | extend 
          TimeGenerated = todatetime(Parts[0]),
          EventType = tostring(Parts[1]),
          Outcome = tostring(Parts[2]),
          Username = extract('user=([^|]+)', 1, RawData),
          SourceIP = extract('src_ip=([^|]+)', 1, RawData),
          AuthMethod = extract('method=([^|]+)', 1, RawData),
          FailureReason = extract('reason=([^|]+)', 1, RawData)
      | project-away RawData, Parts"
  }]
}
// Step 3: Custom ASIM Parser (optional - for normalized queries)
let CustomApp_Auth_Parser = (starttime:datetime=datetime(null)) {
    CustomApp_Auth_CL
    | where isnull(starttime) or TimeGenerated >= starttime
    | extend
        EventType = "Logon",
        EventResult = iff(Outcome == "SUCCESS", "Success", "Failure"),
        TargetUsername = Username,
        SrcIpAddr = SourceIP
};</code></pre>
                    </div>
                    <div class="code-block">
                        <div class="code-header">
                            <span class="code-lang" >Splunk</span>
                            <span class="code-title">props.conf + transforms.conf + CIM mapping</span>
                        </div>
                        <pre><code># inputs.conf (on forwarder)
[monitor:///var/log/myapp/auth.log]
sourcetype = myapp:auth
index = security
# props.conf (on indexer)
[myapp:auth]
TIME_FORMAT = %Y-%m-%dT%H:%M:%S.%3N%Z
TIME_PREFIX = ^
MAX_TIMESTAMP_LOOKAHEAD = 30
SHOULD_LINEMERGE = false
LINE_BREAKER = ([\r\n]+)
KV_MODE = none
# Field extractions
EXTRACT-fields = ^[^\|]+\|(?P<event_type>[^\|]+)\|(?P<outcome>[^\|]+)\|user=(?P<user>[^\|]+)\|src_ip=(?P<src_ip>[^\|]+)\|method=(?P<auth_method>[^\|]+)
EXTRACT-failure = reason=(?P<failure_reason>[^\|]+)
# CIM field aliases
FIELDALIAS-user = user AS src_user
FIELDALIAS-src = src_ip AS src
FIELDALIAS-action = outcome AS action
# eventtypes.conf
[myapp_auth]
search = sourcetype="myapp:auth"
# tags.conf
[eventtype=myapp_auth]
authentication = enabled
default = enabled</code></pre>
                    </div>
                </section>
                <!-- Section 6: Real-World Examples -->
                <section class="content-section" id="examples">
                    <h2><i class="fas fa-building"></i> Real-World Deployment Examples</h2>
                    <div class="example-scenario">
                        <h4>Example 1: Collecting Windows Security Events</h4>
                        <table class="comparison-table">
                            <tr>
                                <th style="width: 15%;">Step</th>
                                <th class="platform-header xsiam">XSIAM</th>
                                <th class="platform-header sentinel">Sentinel</th>
                                <th class="platform-header splunk">Splunk</th>
                            </tr>
                            <tr>
                                <td><strong>1. Agent</strong></td>
                                <td>Install Cortex XDR Agent</td>
                                <td>Install AMA (or via Azure Arc)</td>
                                <td>Install Universal Forwarder</td>
                            </tr>
                            <tr>
                                <td><strong>2. Configure</strong></td>
                                <td>Enable Windows Event collection in agent policy</td>
                                <td>Create DCR with XPath queries for specific EventIDs</td>
                                <td>Deploy inputs.conf via Deployment Server</td>
                            </tr>
                            <tr>
                                <td><strong>3. Filter</strong></td>
                                <td>Dataset rules to filter noise</td>
                                <td>DCR transformKql to project-away or filter</td>
                                <td>transforms.conf to null queue unwanted events</td>
                            </tr>
                            <tr>
                                <td><strong>4. Normalize</strong></td>
                                <td>Auto-mapped to XDM</td>
                                <td>Built-in to SecurityEvent table + ASIM</td>
                                <td>Splunk_TA_windows provides CIM mapping</td>
                            </tr>
                            <tr>
                                <td><strong>5. Query</strong></td>
                                <td><code>datamodel | filter xdm.event.type = AUTH</code></td>
                                <td><code>SecurityEvent | where EventID == 4625</code></td>
                                <td><code>index=wineventlog EventCode=4625</code></td>
                            </tr>
                        </table>
                    </div>
                    <div class="example-scenario">
                        <h4>Example 2: Collecting Firewall Logs via Syslog</h4>
                        <table class="comparison-table">
                            <tr>
                                <th style="width: 15%;">Step</th>
                                <th class="platform-header xsiam">XSIAM</th>
                                <th class="platform-header sentinel">Sentinel</th>
                                <th class="platform-header splunk">Splunk</th>
                            </tr>
                            <tr>
                                <td><strong>1. Collector</strong></td>
                                <td>Deploy Broker VM<br>Enable Syslog Collector applet</td>
                                <td>Deploy Linux VM<br>Install AMA<br>Configure rsyslog</td>
                                <td>Deploy Heavy Forwarder<br>Configure syslog input</td>
                            </tr>
                            <tr>
                                <td><strong>2. Firewall Config</strong></td>
                                <td>Point syslog to Broker VM IP:514</td>
                                <td>Point syslog to Linux VM IP:514</td>
                                <td>Point syslog to HF IP:514</td>
                            </tr>
                            <tr>
                                <td><strong>3. Format</strong></td>
                                <td>CEF recommended (auto-parsed)</td>
                                <td>CEF → CommonSecurityLog<br>or raw syslog</td>
                                <td>CEF or vendor-native<br>TA handles parsing</td>
                            </tr>
                            <tr>
                                <td><strong>4. Parser</strong></td>
                                <td>Install vendor content pack from Marketplace</td>
                                <td>Install solution from Content Hub<br>or use built-in CEF</td>
                                <td>Install TA from Splunkbase<br>Deploy to HF and Indexer</td>
                            </tr>
                            <tr>
                                <td><strong>5. Normalize</strong></td>
                                <td>Data Model Rule maps to XDM</td>
                                <td>ASIM NetworkSession parser</td>
                                <td>TA provides CIM Network_Traffic</td>
                            </tr>
                        </table>
                    </div>
                    <div class="example-scenario">
                        <h4>Example 3: Collecting Cloud Logs (AWS CloudTrail)</h4>
                        <table class="comparison-table">
                            <tr>
                                <th style="width: 15%;">Step</th>
                                <th class="platform-header xsiam">XSIAM</th>
                                <th class="platform-header sentinel">Sentinel</th>
                                <th class="platform-header splunk">Splunk</th>
                            </tr>
                            <tr>
                                <td><strong>1. AWS Setup</strong></td>
                                <td>CloudTrail → S3<br>IAM role for XSIAM</td>
                                <td>CloudTrail → S3<br>or EventBridge → Function</td>
                                <td>CloudTrail → S3<br>or Kinesis Firehose</td>
                            </tr>
                            <tr>
                                <td><strong>2. Connection</strong></td>
                                <td>Data Sources → AWS<br>Configure S3 bucket access</td>
                                <td>Content Hub → AWS solution<br>Deploy Azure Function</td>
                                <td>Splunk Add-on for AWS<br>Configure on HF or SH</td>
                            </tr>
                            <tr>
                                <td><strong>3. Polling</strong></td>
                                <td>XSIAM polls S3 bucket</td>
                                <td>Function polls S3 or receives events</td>
                                <td>Modular input polls SQS/S3</td>
                            </tr>
                            <tr>
                                <td><strong>4. Parser</strong></td>
                                <td>AWS content pack parses JSON</td>
                                <td>AWSCloudTrail table (built-in)</td>
                                <td>Splunk_TA_aws parses to sourcetype</td>
                            </tr>
                            <tr>
                                <td><strong>5. Query</strong></td>
                                <td><code>dataset = aws_cloudtrail_raw</code></td>
                                <td><code>AWSCloudTrail | where EventName == "ConsoleLogin"</code></td>
                                <td><code>sourcetype=aws:cloudtrail eventName=ConsoleLogin</code></td>
                            </tr>
                        </table>
                    </div>
                </section>
                <!-- Section 7: Automation -->
                <section class="content-section" id="automation">
                    <h2><i class="fas fa-robot"></i> Automation & SOAR Comparison</h2>
                    <table class="comparison-table">
                        <thead>
                            <tr>
                                <th style="width: 18%;">Automation Aspect</th>
                                <th class="platform-header xsiam">XSIAM (XSOAR)</th>
                                <th class="platform-header sentinel">Sentinel (Logic Apps)</th>
                                <th class="platform-header splunk">Splunk SOAR</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>SOAR Platform</strong></td>
                                <td>XSOAR built-in</td>
                                <td>Azure Logic Apps</td>
                                <td>Splunk SOAR (Phantom)</td>
                            </tr>
                            <tr>
                                <td><strong>Playbook Creation</strong></td>
                                <td>Visual + Python/YAML</td>
                                <td>Visual Logic Apps Designer</td>
                                <td>Visual + Python</td>
                            </tr>
                            <tr>
                                <td><strong>Integrations</strong></td>
                                <td>800+ content packs</td>
                                <td>500+ Logic Apps connectors</td>
                                <td>300+ Phantom apps</td>
                            </tr>
                            <tr>
                                <td><strong>Trigger Types</strong></td>
                                <td>• Alert/Incident<br>• Schedule<br>• Manual<br>• API webhook</td>
                                <td>• Automation Rule<br>• Manual<br>• Scheduled<br>• HTTP webhook</td>
                                <td>• Notable event<br>• Container<br>• Scheduled<br>• API webhook</td>
                            </tr>
                            <tr>
                                <td><strong>Case Management</strong></td>
                                <td>Built-in War Room<br>Incident timeline</td>
                                <td>Incidents in Defender portal<br>Tasks & evidence</td>
                                <td>Notable events<br>Mission Control</td>
                            </tr>
                        </tbody>
                    </table>
                </section>
                <!-- Interview Preparation -->
                <section class="content-section interview-section" id="interview">
                    <h2><i class="fas fa-user-tie"></i> Interview Preparation</h2>
                    <div class="interview-box">
                        <div class="interview-question">
                            <i class="fas fa-question-circle"></i>
                            <span>Explain the difference between DCR, DCE, and DCRA in Microsoft Sentinel.</span>
                        </div>
                        <div class="interview-answer">
                            <p>These are the building blocks of Sentinel's modern data collection architecture that replaced the legacy Log Analytics agent:</p>
                            <p><strong>DCR (Data Collection Rule)</strong> is the core configuration that defines three things: WHAT data to collect (XPath queries for Windows events, facility/severity for syslog), HOW to transform it (KQL transformation to filter columns or rows), and WHERE to send it (which Log Analytics workspace and table). Think of it as a recipe that tells the agent exactly what to do with data.</p>
                            <p><strong>DCE (Data Collection Endpoint)</strong> is an HTTP endpoint in Azure that receives data from the Logs Ingestion API. When you're sending custom logs via REST API - like from an Azure Function that polls a third-party API - you POST to the DCE. It's also used when AMA needs a regional endpoint for data submission. You create DCEs in specific Azure regions based on where your data sources are.</p>
                            <p><strong>DCRA (Data Collection Rule Association)</strong> is the link between a DCR and a resource. When you want a specific VM to use a particular DCR, you create an association. This is a many-to-many relationship - one DCR can be associated with many VMs, and one VM can have multiple DCRAs for different data types. Azure Policy can automate creating these associations based on tags or resource groups.</p>
                            <p>The flow is: AMA on a VM checks which DCRs are associated with it (via DCRAs), follows the collection rules, applies any transformations, and sends data to the specified workspace. For custom logs, your app POSTs to DCE, the DCR transforms the data, and it lands in your table.</p>
                        </div>
                    </div>
                    <div class="interview-box">
                        <div class="interview-question">
                            <i class="fas fa-question-circle"></i>
                            <span>In Splunk, what's the difference between Universal Forwarder and Heavy Forwarder? When would you use each?</span>
                        </div>
                        <div class="interview-answer">
                            <p>The key difference is processing capability:</p>
                            <p><strong>Universal Forwarder (UF)</strong> is lightweight - about 100MB footprint. It collects data from files, Windows Event Logs, or scripts and forwards it raw to the indexer. It doesn't parse, transform, or index locally. This makes it ideal for endpoints where you want minimal resource usage. The UF can't run modular inputs or apps with dashboards.</p>
                            <p><strong>Heavy Forwarder (HF)</strong> is a full Splunk Enterprise instance with indexing disabled by default. It can do everything a UF can plus: parse and transform data using props.conf and transforms.conf, run modular inputs like DB Connect or API polling, route data to different destinations based on content, mask sensitive data, and filter out unwanted events before they reach the indexer.</p>
                            <p><strong>When to use each:</strong></p>
                            <p>Use <strong>UF</strong> for: endpoint log collection, Windows servers, Linux servers, anywhere you need low footprint and just need to forward logs.</p>
                            <p>Use <strong>HF</strong> for: syslog aggregation from network devices, running modular inputs (DB Connect, API polling), when you need to parse or transform before indexing, routing to multiple destinations, data masking for compliance, DMZ placement where you want to filter before sending to internal indexers.</p>
                            <p>A common architecture is UF on endpoints → HF in DMZ → Indexer cluster. The HF aggregates, parses syslog from firewalls, filters noise, and forwards to indexers. This reduces load on indexers and provides a security boundary.</p>
                        </div>
                    </div>
                    <div class="interview-box">
                        <div class="interview-question">
                            <i class="fas fa-question-circle"></i>
                            <span>How does XSIAM's Broker VM differ from Sentinel's syslog forwarder and Splunk's Heavy Forwarder?</span>
                        </div>
                        <div class="interview-answer">
                            <p>All three serve similar purposes - collecting syslog from network devices - but their architectures differ:</p>
                            <p><strong>XSIAM Broker VM</strong> is a dedicated virtual appliance that runs several "applets" - Syslog Collector, SNMP Collector, and others. You deploy it on-prem or in cloud, register it with your XSIAM tenant, and configure the Syslog Collector to receive logs. The key differentiator is that XSIAM automatically applies parsing rules from installed content packs. CEF and LEEF are auto-parsed. The Broker VM handles the ingest and XSIAM cloud handles the normalization to XDM. You can also do filtering at the Broker VM using parsing rules to drop unwanted data before it's ingested.</p>
                            <p><strong>Sentinel's approach</strong> uses a standard Linux VM running rsyslog or syslog-ng with AMA installed. Syslog data flows: device → rsyslog on Linux VM → AMA → DCR transformation → Log Analytics. For CEF, there's a special configuration that parses CEF into the CommonSecurityLog table with standard fields. The Linux VM is just infrastructure you manage - the intelligence is in the DCR. You need Azure Arc if the VM is on-prem.</p>
                            <p><strong>Splunk's Heavy Forwarder</strong> is the most flexible but requires the most configuration. It's a full Splunk instance, so you have complete control over parsing via props.conf and transforms.conf. You can route different log types to different indexes, mask data, run modular inputs, and even do local indexing. The downside is complexity - you need to manage Splunk configs, apps, and updates on the HF.</p>
                            <p>In terms of ease: Broker VM is simplest (appliance model), Sentinel is moderate (standard Linux + AMA), Splunk HF is most complex but most flexible.</p>
                        </div>
                    </div>
                    <div class="interview-box">
                        <div class="interview-question">
                            <i class="fas fa-question-circle"></i>
                            <span>Compare how each platform handles data normalization. When would you choose ingest-time vs query-time normalization?</span>
                        </div>
                        <div class="interview-answer">
                            <p>Each platform takes a different default approach:</p>
                            <p><strong>XSIAM</strong> uses ingest-time normalization exclusively via XDM. When data arrives, parsing rules extract fields, then data model rules map them to XDM schema. The normalized data is what's stored. Advantage: queries are fast because normalization is done. Disadvantage: less flexibility - if the schema changes, you can't re-normalize historical data.</p>
                            <p><strong>Sentinel</strong> gives you both options. Built-in connectors store data in predefined tables with their own schemas (SigninLogs, SecurityEvent, etc.). For normalization, you can either: (1) Use DCR transformations to normalize at ingest-time into tables like ASimNetworkSessionLogs, or (2) Use ASIM query-time parsers (_Im_NetworkSession) that normalize on the fly. Microsoft recommends ingest-time for performance on high-volume data, query-time for flexibility.</p>
                            <p><strong>Splunk</strong> traditionally uses search-time normalization via CIM. Raw data is indexed, and Technology Add-ons apply field aliases and tags at search time. You can do index-time extraction in props.conf, but CIM mapping is search-time. Data model acceleration pre-computes some of this for performance.</p>
                            <p><strong>When to choose:</strong></p>
                            <p><strong>Ingest-time</strong>: High-volume data where query performance matters, stable schema, compliance requirements for consistent format, cost optimization (store less).</p>
                            <p><strong>Query-time</strong>: Need to preserve raw data for forensics, schema might change, want flexibility to adjust parsing later, troubleshooting where you need original format.</p>
                            <p>I typically recommend: use ingest-time for standard security data (firewall, auth logs), query-time for application logs or when still developing your parsing logic.</p>
                        </div>
                    </div>
                    <div class="interview-box">
                        <div class="interview-question">
                            <i class="fas fa-question-circle"></i>
                            <span>You need to collect logs from a custom application that outputs JSON logs. Walk me through the setup on each platform.</span>
                        </div>
                        <div class="interview-answer">
                            <p>Let me walk through each platform:</p>
                            <p><strong>XSIAM:</strong> First, I'd configure the XDR Collector (which uses Filebeat) on the server to monitor the log file. Create a Filebeat profile in XSIAM that points to the log path. The data arrives in a dataset named after vendor_product. Then I'd create a Parsing Rule using XQL - since it's JSON, I can use json_extract_scalar to pull fields. Finally, create a Data Model Rule to map those fields to XDM for correlation with other data sources.</p>
                            <p><strong>Sentinel:</strong> Install AMA on the server (or Azure Arc if on-prem). Create a custom table in Log Analytics to store the data. Then create a DCR with: (1) a custom text log input pointing to the file path, (2) a transformKql that parses the JSON using parse_json() and extracts fields, (3) destination set to your custom table. Optionally, create a custom ASIM parser function if you want normalized queries.</p>
                            <p><strong>Splunk:</strong> Deploy Universal Forwarder with an inputs.conf monitoring the log path. Set a custom sourcetype. Create props.conf on the indexer with KV_MODE=json for automatic JSON field extraction, or write EXTRACT rules if you need specific fields. Create eventtypes.conf and tags.conf to apply CIM tags if the data maps to a CIM data model.</p>
                            <p>The key differences: XSIAM requires both parsing rule AND data model rule. Sentinel uses DCR transformation. Splunk can auto-extract JSON with KV_MODE=json but might need props.conf tuning. All three can handle JSON natively, but the configuration approaches differ significantly.</p>
                        </div>
                    </div>
                    <div class="interview-box">
                        <div class="interview-question">
                            <i class="fas fa-question-circle"></i>
                            <span>How would you optimize costs when ingesting high-volume logs like firewall traffic?</span>
                        </div>
                        <div class="interview-answer">
                            <p>Cost optimization strategies differ by platform:</p>
                            <p><strong>XSIAM:</strong> Use parsing rules at the Broker VM to drop unwanted events before they're ingested - this is the most effective because you're not paying for data that never enters the platform. Filter out allowed traffic if you only care about blocks, or drop verbose health check logs. Use dataset storage tiers for older data.</p>
                            <p><strong>Sentinel:</strong> Several options: (1) DCR transformations - use 'where' clauses and 'project-away' to filter rows and remove unnecessary columns at ingest time, this reduces billable GB. (2) Use Basic Logs tier for high-volume, low-value data like firewall allows - it's significantly cheaper but has limited query capabilities. (3) New Auxiliary Logs tier (GA April 2025) is even cheaper at $0.15/GB for logs you rarely query. (4) Commitment tiers give up to 50% discount for predictable volumes. (5) Summary rules to aggregate high-volume data.</p>
                            <p><strong>Splunk:</strong> Filter at the Heavy Forwarder using props.conf and transforms.conf to route unwanted events to nullQueue. Use summary indexes to pre-aggregate data and reduce storage needs. Configure index retention policies appropriately. For Splunk Cloud, workload pricing might be better than ingestion pricing for high-volume scenarios.</p>
                            <p>Universal strategy: Only ingest what you need. For firewall logs, do you really need every "allowed" connection, or just the blocks and specific high-risk allows? Filter noise at the earliest point - on the Broker VM, in the DCR, or at the Heavy Forwarder - rather than paying to store and query data you'll never use.</p>
                        </div>
                    </div>
                </section>
                <!-- Summary -->
                <section class="content-section">
                    <h2><i class="fas fa-flag-checkered"></i> Quick Reference Summary</h2>
                    <table class="comparison-table">
                        <thead>
                            <tr>
                                <th>Aspect</th>
                                <th class="platform-header xsiam">XSIAM</th>
                                <th class="platform-header sentinel">Sentinel</th>
                                <th class="platform-header splunk">Splunk</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr><td><strong>Agent</strong></td><td>XDR Agent + XDR Collector</td><td>AMA (Azure Monitor Agent)</td><td>UF + HF</td></tr>
                            <tr><td><strong>Syslog Collector</strong></td><td>Broker VM</td><td>Linux VM + AMA</td><td>Heavy Forwarder</td></tr>
                            <tr><td><strong>Config Management</strong></td><td>Cloud console + Marketplace</td><td>DCR + Azure Policy</td><td>Deployment Server</td></tr>
                            <tr><td><strong>Parsing Config</strong></td><td>Parsing Rules (XQL)</td><td>DCR transformKql (KQL)</td><td>props.conf/transforms.conf</td></tr>
                            <tr><td><strong>Normalization</strong></td><td>XDM (ingest-time)</td><td>ASIM (both options)</td><td>CIM (search-time)</td></tr>
                            <tr><td><strong>Built-in Content</strong></td><td>Marketplace (800+)</td><td>Content Hub (300+)</td><td>Splunkbase (2500+)</td></tr>
                            <tr><td><strong>API Ingestion</strong></td><td>HTTP Log Collector</td><td>Logs Ingestion API + DCE</td><td>HEC</td></tr>
                            <tr><td><strong>SOAR</strong></td><td>XSOAR built-in</td><td>Logic Apps</td><td>Splunk SOAR</td></tr>
                        </tbody>
                    </table>
                </section>
            </main>
        </div>
    </div>
    
    <script>
        function toggleSidebar() {
            const sidebar = document.getElementById('sidebar');
            const mainWrapper = document.getElementById('mainWrapper');
            const overlay = document.getElementById('sidebarOverlay');
            
            if (window.innerWidth <= 768) {
                sidebar.classList.toggle('open');
                overlay.classList.toggle('active');
            } else {
                sidebar.classList.toggle('collapsed');
                mainWrapper.classList.toggle('expanded');
            }
        }
        
        // Q&A toggle
        document.querySelectorAll('.qa-question').forEach(btn => {
            btn.addEventListener('click', () => {
                const answer = btn.nextElementSibling;
                const isOpen = answer.style.display === 'block';
                document.querySelectorAll('.qa-answer').forEach(a => a.style.display = 'none');
                if (!isOpen) answer.style.display = 'block';
            });
        });
        
        // Close sidebar on resize
        window.addEventListener('resize', () => {
            const sidebar = document.getElementById('sidebar');
            const overlay = document.getElementById('sidebarOverlay');
            if (window.innerWidth > 768) {
                sidebar.classList.remove('open');
                overlay.classList.remove('active');
            }
        });
    </script>
</body>
</html>