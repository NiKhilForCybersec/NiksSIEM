<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Splunk Cloud Mastery | Complete Administration Guide</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="shared-styles.css">
    <link rel="stylesheet" href="../assets/css/main.css">
</head>
<body>
    <div class="app-container">
        
    <!-- Sidebar -->
            <aside class="sidebar" id="sidebar">
            <div class="sidebar-header">
                <a href="index.html" class="sidebar-logo"><i class="fas fa-terminal"></i><span>Splunk Reference</span></a>
            </div>
            <div class="sidebar-content">
                <div class="sidebar-section">
                    <div class="sidebar-section-title">Certifications</div>
                    <ul class="sidebar-nav">
                        <li class="sidebar-nav-item"><a href="power-user-certification.html" class="sidebar-nav-link"><i class="fas fa-user-graduate" style="color:#7ce38b"></i>Power User</a></li>
                        <li class="sidebar-nav-item"><a href="admin-certification.html" class="sidebar-nav-link"><i class="fas fa-user-cog" style="color:#f0883e"></i>Admin</a></li>
                        <li class="sidebar-nav-item"><a href="es-admin-certification.html" class="sidebar-nav-link"><i class="fas fa-shield-alt" style="color:#8957e5"></i>ES Admin</a></li>
                        <li class="sidebar-nav-item"><a href="cloud-admin-certification.html" class="sidebar-nav-link"><i class="fas fa-cloud" style="color:#39c5cf"></i>Cloud Admin</a></li>
                    </ul>
                </div>
                <div class="sidebar-section">
                    <div class="sidebar-section-title">SPL Learning</div>
                    <ul class="sidebar-nav">
                        <li class="sidebar-nav-item"><a href="when-to-use-what.html" class="sidebar-nav-link"><i class="fas fa-map-signs" style="color:#f0883e"></i>When to Use What</a></li>
                        <li class="sidebar-nav-item"><a href="spl-practice-questions.html" class="sidebar-nav-link"><i class="fas fa-tasks" style="color:#58a6ff"></i>Practice MCQs</a></li>
                        <li class="sidebar-nav-item"><a href="spl-advanced-mcqs.html" class="sidebar-nav-link"><i class="fas fa-brain" style="color:#a371f7"></i>Advanced MCQs</a></li>
                    </ul>
                </div>
                <div class="sidebar-section">
                    <div class="sidebar-section-title">SPL Reference</div>
                    <ul class="sidebar-nav">
                        <li class="sidebar-nav-item"><a href="spl-fundamentals.html" class="sidebar-nav-link"><i class="fas fa-code"></i>SPL Fundamentals</a></li>
                        <li class="sidebar-nav-item"><a href="spl-intermediate.html" class="sidebar-nav-link"><i class="fas fa-layer-group"></i>SPL Intermediate</a></li>
                        <li class="sidebar-nav-item"><a href="spl-advanced.html" class="sidebar-nav-link"><i class="fas fa-rocket"></i>SPL Advanced</a></li>
                        <li class="sidebar-nav-item"><a href="knowledge-objects.html" class="sidebar-nav-link"><i class="fas fa-lightbulb"></i>Knowledge Objects</a></li>
                        <li class="sidebar-nav-item"><a href="data-models.html" class="sidebar-nav-link"><i class="fas fa-cubes"></i>Data Models</a></li>
                    </ul>
                </div>
                <div class="sidebar-section">
                    <div class="sidebar-section-title">Administration</div>
                    <ul class="sidebar-nav">
                        <li class="sidebar-nav-item"><a href="architecture.html" class="sidebar-nav-link"><i class="fas fa-sitemap"></i>Architecture</a></li>
                        <li class="sidebar-nav-item"><a href="data-ingestion.html" class="sidebar-nav-link"><i class="fas fa-database"></i>Data Ingestion</a></li>
                        <li class="sidebar-nav-item"><a href="forwarders.html" class="sidebar-nav-link"><i class="fas fa-share-alt"></i>Forwarders</a></li>
                        <li class="sidebar-nav-item"><a href="clustering-ha.html" class="sidebar-nav-link"><i class="fas fa-network-wired"></i>Clustering & HA</a></li>
                    </ul>
                </div>
                <div class="sidebar-section">
                    <div class="sidebar-section-title">Enterprise Security</div>
                    <ul class="sidebar-nav">
                        <li class="sidebar-nav-item"><a href="es-overview.html" class="sidebar-nav-link"><i class="fas fa-shield-alt"></i>ES Overview</a></li>
                        <li class="sidebar-nav-item"><a href="correlation-searches.html" class="sidebar-nav-link"><i class="fas fa-search-plus"></i>Correlation Searches</a></li>
                        <li class="sidebar-nav-item"><a href="risk-based-alerting.html" class="sidebar-nav-link"><i class="fas fa-chart-line"></i>Risk-Based Alerting</a></li>
                    </ul>
                </div>
                <div class="sidebar-section">
                    <div class="sidebar-section-title">Resources</div>
                    <ul class="sidebar-nav">
                        <li class="sidebar-nav-item"><a href="lab-exercises.html" class="sidebar-nav-link"><i class="fas fa-flask"></i>Lab Exercises</a></li>
                        <li class="sidebar-nav-item"><a href="troubleshooting.html" class="sidebar-nav-link"><i class="fas fa-wrench"></i>Troubleshooting</a></li>
                    </ul>
                </div>
            </div>
        </aside>
    
    <div class="sidebar-overlay" id="sidebarOverlay" onclick="toggleSidebar()"></div>

        
        <!-- Main Content Wrapper -->
        <div class="main-wrapper" id="mainWrapper">
            <button class="mobile-toggle" onclick="toggleSidebar()" title="Open menu">
                <i class="fas fa-bars"></i>
            </button>
            
            <main class="main-content">
                <div class="breadcrumb">
                    <a href="index.html">Home</a>
                    <span class="separator">/</span>
                    <a href="index.html">Splunk</a>
                    <span class="separator">/</span>
                    <span class="current">Cloud Mastery</span>
                </div>

                <h1><i class="fas fa-cloud-upload-alt"></i> Splunk Cloud Mastery - Complete Administration Guide</h1>
                <p class="lead">Everything you need to administer Splunk Cloud for an enterprise retail environment. Complete coverage of IDM, ACS, data ingestion, app management, troubleshooting, and cost optimization. Designed for Sobeys-scale deployments with 500GB+/day ingestion.</p>

                <!-- Quick Reference -->
                <div class="info-box info-box-primary">
                    <h4><i class="fas fa-bolt"></i> Splunk Cloud Quick Reference</h4>
                    <table class="compact-table">
                        <tr><td><strong>Deployment Types</strong></td><td>Splunk Cloud Platform (SCP), Splunk Cloud Classic, Victoria Experience</td></tr>
                        <tr><td><strong>Admin Portals</strong></td><td>Splunk Web, Admin Config Service (ACS), Cloud Services Portal</td></tr>
                        <tr><td><strong>Data Inputs</strong></td><td>Universal Forwarder, HEC, S3, Kinesis, Cloud-to-Cloud (C2C)</td></tr>
                        <tr><td><strong>Support Tiers</strong></td><td>Standard, Enhanced, Mission Critical</td></tr>
                        <tr><td><strong>SLA</strong></td><td>99.9% uptime (Enhanced), 99.95% (Mission Critical)</td></tr>
                        <tr><td><strong>Maintenance Windows</strong></td><td>Sundays 2:00-6:00 AM local (configurable)</td></tr>
                    </table>
                </div>

                <!-- Shared Responsibility Model -->
                <h2><i class="fas fa-handshake"></i> Shared Responsibility Model</h2>
                
                <div class="config-section">
                    <h3>What You Manage vs What Splunk Manages</h3>
                    <div class="arch-diagram">
SPLUNK CLOUD SHARED RESPONSIBILITY MODEL
════════════════════════════════════════════════════════════════════════════════

┌─────────────────────────────────────────────────────────────────────────────┐
│                    CUSTOMER RESPONSIBILITY                                   │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│   DATA & CONTENT                      CONFIGURATION                         │
│   ══════════════                      ═════════════                         │
│   • Data onboarding decisions         • Index creation & retention          │
│   • Sourcetype definitions            • User & role management              │
│   • Field extractions                 • App installation requests           │
│   • Knowledge objects                 • Search optimization                 │
│   • Dashboards & reports              • Alert configuration                 │
│   • Saved searches                    • HEC token management                │
│   • Lookup files                      • Forwarder deployment                │
│                                                                              │
│   SECURITY                            OPERATIONS                            │
│   ════════                            ══════════                            │
│   • User access management            • Data quality monitoring             │
│   • SAML/SSO configuration            • Search performance tuning           │
│   • IP allowlisting                   • Capacity planning requests          │
│   • Data classification               • Maintenance window selection        │
│   • Compliance requirements           • Support ticket management           │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────────────────┐
│                    SPLUNK RESPONSIBILITY                                     │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│   INFRASTRUCTURE                      PLATFORM                              │
│   ══════════════                      ════════                              │
│   • Physical/virtual servers          • Splunk software upgrades            │
│   • Network infrastructure            • Security patches                    │
│   • Storage management                • Platform availability (SLA)         │
│   • Compute scaling                   • Disaster recovery                   │
│   • Data replication                  • Backup management                   │
│                                                                              │
│   SECURITY                            COMPLIANCE                            │
│   ════════                            ══════════                            │
│   • Infrastructure security           • SOC 2 Type II                       │
│   • Encryption at rest                • ISO 27001                           │
│   • Encryption in transit             • HIPAA (with BAA)                    │
│   • Vulnerability management          • FedRAMP (GovCloud)                  │
│   • Intrusion detection               • PCI DSS (shared)                    │
│                                                                              │
│   OPERATIONS                          SUPPORT                               │
│   ══════════                          ═══════                               │
│   • 24/7 monitoring                   • Technical support                   │
│   • Incident response                 • Professional services               │
│   • Capacity management               • Documentation                       │
│   • Performance optimization          • Training resources                  │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘

GRAY AREAS - SHARED RESPONSIBILITY
──────────────────────────────────────────────────────────────────────────────
• App vetting: Customer submits, Splunk reviews and installs
• Index management: Customer defines, Splunk provisions
• Performance issues: Customer optimizes searches, Splunk scales infra
• Security incidents: Customer manages access, Splunk manages platform
                    </div>
                </div>

                <!-- Admin Config Service (ACS) -->
                <h2><i class="fas fa-cogs"></i> Admin Config Service (ACS) - Self-Service Administration</h2>
                
                <div class="config-section">
                    <h3>ACS Overview & Capabilities</h3>
                    <p>ACS provides programmatic access to Splunk Cloud administration tasks that previously required support tickets. This enables automation and faster configuration changes.</p>

                    <div class="config-block">
                        <div class="config-block-header">
                            <span class="config-title">ACS API Authentication & Setup</span>
                        </div>
                        <pre><code># ACS AUTHENTICATION
# ════════════════════════════════════════════════════════════════════════════

# 1. Generate ACS Token (Splunk Web → Settings → Tokens)
# Token requires: sc_admin capability

# 2. Set environment variables
export SPLUNK_CLOUD_STACK="acme.splunkcloud.com"
export ACS_TOKEN="your-acs-token-here"

# 3. Test connection
curl -X GET "https://admin.splunk.com/${SPLUNK_CLOUD_STACK}/adminconfig/v2/status" \
  -H "Authorization: Bearer ${ACS_TOKEN}" \
  -H "Content-Type: application/json"

# Expected response:
# {"status": "healthy", "stack": "acme.splunkcloud.com"}


# ACS API ENDPOINTS
# ════════════════════════════════════════════════════════════════════════════

Base URL: https://admin.splunk.com/{stack}/adminconfig/v2

Endpoints:
├── /indexes              - Index management
├── /inputs/http          - HEC token management
├── /access/outbound-ports - Outbound connectivity
├── /access/tokens        - Token management
├── /limits               - Search limits configuration
├── /apps                 - App management
├── /maintenance-windows  - Maintenance scheduling
└── /status               - Stack health status</code></pre>
                    </div>

                    <div class="config-block">
                        <div class="config-block-header">
                            <span class="config-title">Index Management via ACS</span>
                        </div>
                        <pre><code># CREATE NEW INDEX
# ════════════════════════════════════════════════════════════════════════════

# Sobeys example: Create index for POS transactions
curl -X POST "https://admin.splunk.com/${SPLUNK_CLOUD_STACK}/adminconfig/v2/indexes" \
  -H "Authorization: Bearer ${ACS_TOKEN}" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "pos_transactions",
    "datatype": "event",
    "searchableDays": 90,
    "maxDataSizeMB": 500000,
    "splunk_archival_retention_days": 365
  }'

# CREATE METRICS INDEX
curl -X POST "https://admin.splunk.com/${SPLUNK_CLOUD_STACK}/adminconfig/v2/indexes" \
  -H "Authorization: Bearer ${ACS_TOKEN}" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "pos_metrics",
    "datatype": "metric",
    "searchableDays": 30,
    "maxDataSizeMB": 100000
  }'

# LIST ALL INDEXES
curl -X GET "https://admin.splunk.com/${SPLUNK_CLOUD_STACK}/adminconfig/v2/indexes" \
  -H "Authorization: Bearer ${ACS_TOKEN}"

# UPDATE INDEX RETENTION
curl -X PATCH "https://admin.splunk.com/${SPLUNK_CLOUD_STACK}/adminconfig/v2/indexes/pos_transactions" \
  -H "Authorization: Bearer ${ACS_TOKEN}" \
  -H "Content-Type: application/json" \
  -d '{
    "searchableDays": 180
  }'

# DELETE INDEX (careful!)
curl -X DELETE "https://admin.splunk.com/${SPLUNK_CLOUD_STACK}/adminconfig/v2/indexes/test_index" \
  -H "Authorization: Bearer ${ACS_TOKEN}"


# INDEX NAMING CONVENTION FOR SOBEYS
# ════════════════════════════════════════════════════════════════════════════
# pos_transactions     - POS transaction logs
# pos_metrics          - POS performance metrics
# security_events      - Security-relevant events
# network_firewall     - Firewall logs
# network_proxy        - Proxy/web gateway
# endpoint_windows     - Windows event logs
# endpoint_linux       - Linux syslog
# app_sap             - SAP application logs
# app_ecommerce       - E-commerce platform
# infra_cloud         - Cloud infrastructure (AWS/Azure)
# summary_*           - Summary indexes for acceleration</code></pre>
                    </div>

                    <div class="config-block">
                        <div class="config-block-header">
                            <span class="config-title">HEC Token Management via ACS</span>
                        </div>
                        <pre><code># CREATE HEC TOKEN
# ════════════════════════════════════════════════════════════════════════════

# Production HEC token for POS systems
curl -X POST "https://admin.splunk.com/${SPLUNK_CLOUD_STACK}/adminconfig/v2/inputs/http" \
  -H "Authorization: Bearer ${ACS_TOKEN}" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "pos_ingest_prod",
    "description": "HEC token for POS transaction ingestion - Production",
    "indexes": ["pos_transactions", "pos_metrics"],
    "index": "pos_transactions",
    "sourcetype": "pos:transactions",
    "disabled": false,
    "useACK": true
  }'

# Response includes the token value - store securely!
# {
#   "name": "pos_ingest_prod",
#   "token": "12345678-abcd-1234-efgh-567890abcdef",
#   ...
# }

# LIST ALL HEC TOKENS
curl -X GET "https://admin.splunk.com/${SPLUNK_CLOUD_STACK}/adminconfig/v2/inputs/http" \
  -H "Authorization: Bearer ${ACS_TOKEN}"

# UPDATE HEC TOKEN (add index)
curl -X PATCH "https://admin.splunk.com/${SPLUNK_CLOUD_STACK}/adminconfig/v2/inputs/http/pos_ingest_prod" \
  -H "Authorization: Bearer ${ACS_TOKEN}" \
  -H "Content-Type: application/json" \
  -d '{
    "indexes": ["pos_transactions", "pos_metrics", "pos_audit"]
  }'

# DISABLE HEC TOKEN (security incident response)
curl -X PATCH "https://admin.splunk.com/${SPLUNK_CLOUD_STACK}/adminconfig/v2/inputs/http/compromised_token" \
  -H "Authorization: Bearer ${ACS_TOKEN}" \
  -H "Content-Type: application/json" \
  -d '{
    "disabled": true
  }'

# DELETE HEC TOKEN
curl -X DELETE "https://admin.splunk.com/${SPLUNK_CLOUD_STACK}/adminconfig/v2/inputs/http/old_token" \
  -H "Authorization: Bearer ${ACS_TOKEN}"


# HEC TOKEN BEST PRACTICES
# ════════════════════════════════════════════════════════════════════════════
# • One token per data source/application
# • Enable indexer acknowledgment (useACK) for critical data
# • Restrict to specific indexes
# • Rotate tokens quarterly
# • Monitor token usage: index=_internal sourcetype=splunkd_access HEC</code></pre>
                    </div>

                    <div class="config-block">
                        <div class="config-block-header">
                            <span class="config-title">Outbound Connectivity via ACS</span>
                        </div>
                        <pre><code># CONFIGURE OUTBOUND PORTS
# ════════════════════════════════════════════════════════════════════════════

# Enable outbound connectivity for webhook alerts
curl -X POST "https://admin.splunk.com/${SPLUNK_CLOUD_STACK}/adminconfig/v2/access/outbound-ports" \
  -H "Authorization: Bearer ${ACS_TOKEN}" \
  -H "Content-Type: application/json" \
  -d '{
    "outboundPorts": [
      {
        "port": 443,
        "subnets": ["0.0.0.0/0"],
        "destinationHostnames": ["hooks.slack.com", "*.service-now.com"]
      },
      {
        "port": 9997,
        "subnets": ["10.0.0.0/8"],
        "destinationHostnames": []
      }
    ]
  }'

# Common outbound requirements:
# • ServiceNow: 443 to *.service-now.com
# • Slack: 443 to hooks.slack.com
# • Teams: 443 to outlook.office.com
# • PagerDuty: 443 to events.pagerduty.com
# • Splunk SOAR: 443 to your SOAR instance</code></pre>
                    </div>
                </div>

                <!-- Data Ingestion Methods -->
                <h2><i class="fas fa-upload"></i> Data Ingestion Methods</h2>
                
                <div class="config-section">
                    <h3>Complete Ingestion Options for Splunk Cloud</h3>
                    <div class="arch-diagram">
SPLUNK CLOUD DATA INGESTION METHODS
════════════════════════════════════════════════════════════════════════════════

METHOD 1: UNIVERSAL FORWARDER (Recommended for on-prem)
──────────────────────────────────────────────────────────────────────────────

┌─────────────────┐         ┌─────────────────┐         ┌─────────────────┐
│   Data Source   │         │   Universal     │         │  Splunk Cloud   │
│   ═══════════   │────────▶│   Forwarder     │────────▶│  ═══════════    │
│ • Windows Server│  Logs   │   ═══════════   │  TCP    │                 │
│ • Linux Server  │         │ • Lightweight   │  9997   │  IDM manages    │
│ • Application   │         │ • 50MB install  │ (TLS)   │  forwarder      │
│                 │         │ • Local parsing │         │  connections    │
└─────────────────┘         └─────────────────┘         └─────────────────┘

Setup:
1. Download UF from Splunk Cloud (includes cloud certificates)
2. Install on source server
3. Configure outputs.conf with cloud indexers
4. Deploy inputs.conf for data collection

Sobeys Volume: ~200GB/day from 1,500 stores


METHOD 2: HTTP EVENT COLLECTOR (HEC) - APIs & Cloud Services
──────────────────────────────────────────────────────────────────────────────

┌─────────────────┐         ┌─────────────────────────────────────────────┐
│   Application   │ HTTPS   │              Splunk Cloud HEC               │
│   ═══════════   │────────▶│              ═════════════════              │
│ • Custom App    │ POST    │                                             │
│ • Cloud Service │ JSON    │  https://http-inputs-acme.splunkcloud.com   │
│ • IoT Device    │         │                                             │
│ • Container     │         │  Headers:                                   │
└─────────────────┘         │  Authorization: Splunk <token>              │
                            │  Content-Type: application/json              │
                            └─────────────────────────────────────────────┘

Example HEC POST:
curl "https://http-inputs-acme.splunkcloud.com/services/collector/event" \
  -H "Authorization: Splunk 12345678-abcd-1234-efgh-567890abcdef" \
  -d '{"event": {"transaction_id": "TXN-001", "amount": 125.50, "store": "STR-001"}}'

Sobeys Use Cases: POS API events, mobile app telemetry, cloud functions


METHOD 3: CLOUD-TO-CLOUD (C2C) INPUTS - SaaS Integration
──────────────────────────────────────────────────────────────────────────────

┌─────────────────┐                           ┌─────────────────┐
│   Cloud SaaS    │    Splunk Cloud APIs      │  Splunk Cloud   │
│   ══════════    │◀─────────────────────────▶│  ═══════════    │
│ • Microsoft 365 │    OAuth/API Keys         │                 │
│ • AWS           │                           │  Native C2C     │
│ • Salesforce    │    Pull data on schedule  │  connectors     │
│ • Okta          │                           │                 │
└─────────────────┘                           └─────────────────┘

Available C2C Inputs (Splunk Web → Settings → Data Inputs → Cloud):
• Microsoft 365 Management Activity
• AWS CloudTrail, CloudWatch, S3
• Google Workspace
• Okta System Log
• Salesforce Event Monitoring
• Zoom
• Box

Sobeys Use Cases: O365 audit logs, AWS infrastructure, Okta authentication


METHOD 4: S3-BASED INGESTION - Bulk/Archive Data
──────────────────────────────────────────────────────────────────────────────

┌─────────────────┐         ┌─────────────────┐         ┌─────────────────┐
│   AWS S3        │         │  Splunk Cloud   │         │   Indexed       │
│   ══════════    │────────▶│  S3 Input       │────────▶│   Data          │
│ • Log archives  │  SQS    │  ═══════════    │         │   ════════════  │
│ • CloudTrail    │  notify │ • Polls S3      │         │ • Searchable    │
│ • VPC Flow      │         │ • Processes     │         │ • Retained      │
│                 │         │   files         │         │                 │
└─────────────────┘         └─────────────────┘         └─────────────────┘

Configuration requires:
• IAM role for Splunk Cloud to assume
• S3 bucket policy
• SQS queue for notifications
• Sourcetype definitions


METHOD 5: DATA MANAGER (IDM) - Centralized Forwarder Management
──────────────────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────────────────────┐
│                      SPLUNK CLOUD DATA MANAGER (IDM)                        │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│   Features:                                                                  │
│   • Centralized forwarder deployment                                        │
│   • Configuration management                                                 │
│   • Health monitoring                                                        │
│   • Certificate management                                                   │
│   • App deployment to forwarders                                            │
│                                                                              │
│   Accessible via: Splunk Web → Settings → Data Manager                      │
│                                                                              │
│   Forwarder Groups:                                                          │
│   ├── windows_servers (500 UFs)                                             │
│   ├── linux_servers (200 UFs)                                               │
│   ├── pos_systems (1,500 UFs)                                               │
│   └── network_devices (50 HFs)                                              │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
                    </div>
                </div>

                <!-- Ingest Actions -->
                <h2><i class="fas fa-filter"></i> Ingest Actions - Data Pipeline Management</h2>
                
                <div class="config-section">
                    <h3>Filter, Route, and Transform at Ingestion</h3>
                    <p>Ingest Actions allow you to process data before indexing, reducing storage costs and improving data quality without Heavy Forwarders.</p>

                    <div class="config-block">
                        <div class="config-block-header">
                            <span class="config-title">Ingest Actions Configuration</span>
                        </div>
                        <pre><code># INGEST ACTIONS - Splunk Web → Settings → Ingest Actions
# ════════════════════════════════════════════════════════════════════════════

# ACTION 1: FILTER - Drop unwanted events (reduce license)
# ────────────────────────────────────────────────────────────────────────────
# Sobeys example: Drop debug-level POS logs

Rule Name: drop_pos_debug
Ruleset: pos_data_pipeline
Match Criteria: 
  - sourcetype = pos:transactions
  - log_level = "DEBUG"
Action: Filter (drop events)

# Expected savings: ~15% of POS volume = 30GB/day


# ACTION 2: ROUTE - Send to different indexes based on content
# ────────────────────────────────────────────────────────────────────────────
# Sobeys example: Route failed transactions to security index

Rule Name: route_failed_transactions
Ruleset: pos_data_pipeline
Match Criteria:
  - sourcetype = pos:transactions
  - status = "failed" OR status = "declined"
Action: Route to index "security_events"

# Enables security team to focus on anomalies


# ACTION 3: MASK - Redact sensitive data (PCI compliance)
# ────────────────────────────────────────────────────────────────────────────
# Sobeys example: Mask credit card numbers

Rule Name: mask_card_numbers
Ruleset: pos_data_pipeline
Match Criteria:
  - sourcetype = pos:transactions
Mask Pattern: \b(\d{4})\d{8}(\d{4})\b
Replacement: $1********$2

# Before: card_number=4532123456781234
# After:  card_number=4532********1234


# ACTION 4: TRANSFORM - Modify field values
# ────────────────────────────────────────────────────────────────────────────
# Sobeys example: Normalize store identifiers

Rule Name: normalize_store_id
Ruleset: pos_data_pipeline
Match Criteria:
  - sourcetype = pos:transactions
Transformation: 
  - Extract store_id from field location
  - Format as "STR-" + zero-padded number


# INGEST ACTIONS PIPELINE ORDER
# ════════════════════════════════════════════════════════════════════════════

┌─────────────────────────────────────────────────────────────────────────────┐
│                         INGEST ACTIONS PIPELINE                              │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│   Raw Data → [FILTER] → [MASK] → [TRANSFORM] → [ROUTE] → Index              │
│              (drop)    (redact)  (modify)     (direct)                      │
│                                                                              │
│   Processing order matters!                                                  │
│   1. Filter first (don't process data you'll drop)                          │
│   2. Mask sensitive data                                                     │
│   3. Transform/normalize                                                     │
│   4. Route to appropriate index                                              │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘


# TESTING INGEST ACTIONS
# ════════════════════════════════════════════════════════════════════════════

# Use Preview mode to test before enabling
# 1. Create rule in Preview mode
# 2. Send sample data via HEC
# 3. Check preview results
# 4. Enable when validated

# Monitor Ingest Actions performance:
index=_internal sourcetype=splunkd component=IngestActions
| stats count by action_name, result
| sort -count</code></pre>
                    </div>
                </div>

                <!-- App Management -->
                <h2><i class="fas fa-puzzle-piece"></i> App Management in Splunk Cloud</h2>
                
                <div class="config-section">
                    <h3>App Vetting & Installation Process</h3>
                    <div class="config-block">
                        <div class="config-block-header">
                            <span class="config-title">App Installation Workflow</span>
                        </div>
                        <pre><code># SPLUNK CLOUD APP CATEGORIES
# ════════════════════════════════════════════════════════════════════════════

# 1. SELF-SERVICE APPS (Splunkbase - Cloud Compatible)
#    - Install directly from Splunk Web
#    - Pre-vetted for Cloud compatibility
#    - Look for "Cloud Compatible" badge

# 2. ADMIN-ASSISTED APPS (Require ticket)
#    - Apps with custom commands
#    - Apps requiring configuration files
#    - Apps with scripted inputs

# 3. PRIVATE APPS (Customer-developed)
#    - Must pass Splunk App Vetting (AppInspect)
#    - Submit via Support ticket
#    - Typical turnaround: 3-5 business days


# APP VETTING PROCESS
# ════════════════════════════════════════════════════════════════════════════

# Step 1: Run AppInspect locally before submitting
pip install splunk-appinspect

# Basic check
splunk-appinspect inspect your_app.tgz --mode precert

# Cloud-specific checks
splunk-appinspect inspect your_app.tgz --included-tags cloud

# Generate report
splunk-appinspect inspect your_app.tgz --mode precert --output-file report.json

# Common AppInspect failures:
# • Hardcoded passwords in configs
# • Non-standard directory structure
# • Unsupported scripted inputs
# • Custom search commands without proper packaging
# • Missing app.conf settings


# ESSENTIAL APPS FOR SOBEYS DEPLOYMENT
# ════════════════════════════════════════════════════════════════════════════

Security & Compliance:
├── Splunk Enterprise Security (ES)
├── Splunk SOAR
├── Splunk Security Essentials
├── InfoSec App for Splunk
└── PCI Compliance for Splunk

Data Inputs (TAs):
├── Splunk Add-on for Microsoft Windows
├── Splunk Add-on for Unix and Linux
├── Splunk Add-on for Palo Alto Networks
├── Splunk Add-on for AWS
├── Splunk Add-on for Microsoft Office 365
├── Splunk Connect for SAP
└── Splunk Add-on for CrowdStrike

Visualization & Analysis:
├── Splunk Dashboard Studio
├── Lookup File Editor
├── Search Head Clustering Dashboard
└── Monitoring Console (built-in)

IT Operations:
├── Splunk IT Service Intelligence (ITSI)
├── Splunk Observability
└── Splunk Infrastructure Monitoring


# REQUESTING APP INSTALLATION
# ════════════════════════════════════════════════════════════════════════════

# Via ACS API (supported apps):
curl -X POST "https://admin.splunk.com/${SPLUNK_CLOUD_STACK}/adminconfig/v2/apps/victoria" \
  -H "Authorization: Bearer ${ACS_TOKEN}" \
  -H "Content-Type: application/json" \
  -d '{
    "packageURL": "https://splunkbase.splunk.com/app/1234/release/2.0.0/download",
    "name": "app_name"
  }'

# Via Support Ticket (private/complex apps):
# 1. Open case at https://support.splunk.com
# 2. Attach app package (.tgz) and AppInspect report
# 3. Specify target: search heads, indexers, or both
# 4. Provide installation priority: standard or urgent</code></pre>
                    </div>
                </div>

                <!-- User & Access Management -->
                <h2><i class="fas fa-users-cog"></i> User & Access Management</h2>
                
                <div class="config-section">
                    <h3>SAML SSO & Role-Based Access</h3>
                    <div class="config-block">
                        <div class="config-block-header">
                            <span class="config-title">SAML Configuration for Enterprise SSO</span>
                        </div>
                        <pre><code># SAML SSO CONFIGURATION
# ════════════════════════════════════════════════════════════════════════════

# Splunk Cloud supports SAML 2.0 with major IdPs:
# • Azure AD
# • Okta
# • Ping Identity
# • ADFS
# • OneLogin

# AZURE AD INTEGRATION (Common for Sobeys)
# ────────────────────────────────────────────────────────────────────────────

# 1. In Azure AD:
#    - Create Enterprise Application
#    - Select "Splunk Cloud Platform" from gallery
#    - Configure SAML settings:
#      - Identifier (Entity ID): https://acme.splunkcloud.com
#      - Reply URL: https://acme.splunkcloud.com/saml/acs
#      - Sign-on URL: https://acme.splunkcloud.com

# 2. In Splunk Cloud (Settings → Authentication → SAML):
#    - Import IdP metadata from Azure AD
#    - Configure attribute mappings:
#      - realName: http://schemas.xmlsoap.org/ws/2005/05/identity/claims/displayname
#      - mail: http://schemas.xmlsoap.org/ws/2005/05/identity/claims/emailaddress
#      - role: http://schemas.microsoft.com/ws/2008/06/identity/claims/groups


# ROLE-BASED ACCESS CONTROL
# ════════════════════════════════════════════════════════════════════════════

# Sobeys Role Hierarchy:
┌─────────────────────────────────────────────────────────────────────────────┐
│ ROLE                    │ CAPABILITIES              │ INDEX ACCESS          │
├─────────────────────────┼───────────────────────────┼───────────────────────┤
│ sc_admin                │ Full Splunk Cloud admin   │ All indexes           │
│ es_admin                │ ES administration         │ Security indexes      │
│ soc_analyst_l3          │ Full investigation        │ All security indexes  │
│ soc_analyst_l2          │ Investigation + alerts    │ Security indexes      │
│ soc_analyst_l1          │ Alert triage only         │ Notable events only   │
│ retail_analyst          │ POS data analysis         │ pos_*, inventory_*    │
│ it_operations           │ Infrastructure monitoring │ infra_*, endpoint_*   │
│ auditor                 │ Read-only compliance      │ All (read-only)       │
│ developer               │ App development           │ dev_*, test_*         │
└─────────────────────────┴───────────────────────────┴───────────────────────┘

# Creating Custom Role (Splunk Web → Settings → Roles)
Role Name: retail_analyst
Inheritance: user
Capabilities:
  - search
  - rtsearch
  - schedule_search
  - list_inputs
  
Index Permissions:
  Included: pos_transactions, pos_metrics, inventory_*, default
  Excluded: security_*, _internal, _audit
  
Search Restrictions:
  Search Filter: store_region="Atlantic" OR store_region="Ontario"
  (Limits analyst to their region only)


# IP ALLOWLISTING
# ════════════════════════════════════════════════════════════════════════════

# Restrict access to corporate networks only
# Settings → Server Settings → IP Allow List

# Sobeys allowed networks:
# 10.0.0.0/8       - Corporate internal
# 172.16.0.0/12    - VPN clients  
# 192.168.0.0/16   - Remote offices
# 203.0.113.50/32  - SOC jumpbox

# Note: IP allowlisting affects Splunk Web access only
# HEC and forwarder connections use separate controls</code></pre>
                    </div>
                </div>

                <!-- Troubleshooting -->
                <h2><i class="fas fa-wrench"></i> Splunk Cloud Troubleshooting</h2>
                
                <div class="config-section">
                    <h3>Common Issues & Resolutions</h3>
                    <div class="arch-diagram">
SPLUNK CLOUD TROUBLESHOOTING GUIDE
════════════════════════════════════════════════════════════════════════════════

ISSUE 1: DATA NOT ARRIVING
──────────────────────────────────────────────────────────────────────────────
Symptoms: 
• No new events in index
• Forwarders showing connected but no data

Diagnostic Steps:
┌─────────────────────────────────────────────────────────────────────────────┐
│ # 1. Check forwarder connectivity                                          │
│ index=_internal sourcetype=splunkd host=<forwarder> group=tcpin_connections│
│ | stats latest(status) by host                                             │
│                                                                             │
│ # 2. Check for ingestion errors                                            │
│ index=_internal sourcetype=splunkd ERROR earliest=-1h                      │
│ | stats count by message                                                   │
│                                                                             │
│ # 3. Verify HEC token (if applicable)                                      │
│ index=_internal sourcetype=splunkd_access method=POST "/services/collector"│
│ | stats count by status                                                    │
│                                                                             │
│ # 4. Check license usage                                                   │
│ | rest /services/licenser/pools                                            │
│ | stats sum(used_bytes) as used, sum(effective_quota) as quota             │
│ | eval pct_used = round(used/quota*100, 1)                                 │
└─────────────────────────────────────────────────────────────────────────────┘

Common Causes:
• Forwarder certificate expired → Re-download from Cloud
• HEC token disabled → Re-enable via ACS
• Network firewall blocking 9997/8088 → Update firewall rules
• License exceeded → Contact Splunk for temporary increase


ISSUE 2: SLOW SEARCHES
──────────────────────────────────────────────────────────────────────────────
Symptoms:
• Searches timing out
• Dashboard slow to load
• "Job inspector" shows high disk/network time

Diagnostic Steps:
┌─────────────────────────────────────────────────────────────────────────────┐
│ # 1. Use Job Inspector (Job → Inspect Job)                                 │
│ Check: scan_count, result_count, execution_time                            │
│                                                                             │
│ # 2. Identify expensive searches                                           │
│ index=_audit action=search info=completed                                  │
│ | stats avg(total_run_time) as avg_time, count by user, search             │
│ | where avg_time > 300                                                     │
│ | sort -avg_time                                                           │
│                                                                             │
│ # 3. Check search concurrency                                              │
│ | rest /services/search/jobs                                               │
│ | stats count by dispatchState                                             │
└─────────────────────────────────────────────────────────────────────────────┘

Optimization Actions:
• Add index=<specific> to narrow search scope
• Use earliest/latest time bounds
• Replace wildcard (*) with specific values
• Use tstats instead of stats for data model searches
• Schedule heavy searches during off-peak hours


ISSUE 3: HEC ERRORS
──────────────────────────────────────────────────────────────────────────────
Symptoms:
• HTTP 401 Unauthorized
• HTTP 403 Forbidden
• HTTP 400 Bad Request

Error Codes and Solutions:
┌─────────────────────────────────────────────────────────────────────────────┐
│ Error Code │ Meaning                    │ Solution                         │
├────────────┼────────────────────────────┼──────────────────────────────────┤
│ 401        │ Invalid/missing token      │ Verify token in Authorization    │
│ 403        │ Token disabled or IP block │ Check token status, IP allowlist │
│ 400        │ Malformed JSON             │ Validate JSON payload            │
│ 503        │ HEC overloaded             │ Implement retry with backoff     │
│ 500        │ Internal error             │ Check _internal for details      │
└─────────────────────────────────────────────────────────────────────────────┘

# HEC Health Check Query:
index=_internal sourcetype=splunkd_access uri="/services/collector*"
| stats count by status, clientip
| sort -count


ISSUE 4: FORWARDER CERTIFICATE ISSUES
──────────────────────────────────────────────────────────────────────────────
Symptoms:
• Forwarder shows "connection refused"
• SSL handshake failures in splunkd.log

Resolution:
┌─────────────────────────────────────────────────────────────────────────────┐
│ # 1. Check certificate expiration                                          │
│ openssl x509 -in $SPLUNK_HOME/etc/auth/cacert.pem -noout -dates           │
│                                                                             │
│ # 2. Re-download credentials package from Splunk Cloud                     │
│ Splunk Web → Settings → Forwarder Management → Download Credentials        │
│                                                                             │
│ # 3. Deploy new credentials to forwarder                                   │
│ tar -xzf splunkclouduf.spl -C $SPLUNK_HOME/etc/apps/                       │
│ $SPLUNK_HOME/bin/splunk restart                                            │
└─────────────────────────────────────────────────────────────────────────────┘


ISSUE 5: SEARCH HEAD CLUSTER ISSUES (Victoria)
──────────────────────────────────────────────────────────────────────────────
Symptoms:
• Knowledge objects not syncing
• Some saved searches missing
• Dashboard discrepancies between sessions

Diagnostic:
┌─────────────────────────────────────────────────────────────────────────────┐
│ # Check SHC status                                                         │
│ | rest /services/shcluster/status                                          │
│ | table label, status, last_heartbeat                                      │
│                                                                             │
│ # Check replication status                                                 │
│ | rest /services/shcluster/member/consensus                                │
│ | table label, status, generation_id                                       │
└─────────────────────────────────────────────────────────────────────────────┘

Note: Most SHC issues in Splunk Cloud require Support ticket
                    </div>
                </div>

                <!-- Cost Optimization -->
                <h2><i class="fas fa-dollar-sign"></i> Cost Optimization Strategies</h2>
                
                <div class="config-section">
                    <h3>Reduce Costs Without Sacrificing Value</h3>
                    <div class="config-block">
                        <div class="config-block-header">
                            <span class="config-title">License & Storage Optimization</span>
                        </div>
                        <pre><code># SPLUNK CLOUD COST FACTORS
# ════════════════════════════════════════════════════════════════════════════

# Primary cost drivers:
# 1. Daily Ingestion Volume (GB/day) - Most significant
# 2. Storage/Retention (searchable days)
# 3. Search Compute (SVCs - Splunk Virtual Compute)
# 4. Premium Apps (ES, ITSI, SOAR)


# STRATEGY 1: REDUCE INGESTION VOLUME
# ════════════════════════════════════════════════════════════════════════════

# Identify high-volume, low-value sourcetypes
index=* earliest=-7d
| stats sum(eval(len(_raw))) as bytes by sourcetype
| eval GB = round(bytes/1024/1024/1024, 2)
| sort -GB
| head 20

# Common candidates for reduction at Sobeys:
# • Debug logs (filter at source or Ingest Actions)
# • Verbose Windows events (tune WEF subscriptions)
# • Health check/heartbeat events (aggregate or sample)
# • Duplicate logs (sent from multiple sources)

# Calculate potential savings by filtering debug logs:
index=pos_transactions log_level="DEBUG" earliest=-24h
| stats sum(eval(len(_raw))) as debug_bytes
| eval daily_GB_saved = round(debug_bytes/1024/1024/1024, 2)
| eval monthly_savings = "$" . tostring(daily_GB_saved * 30 * 15, "commas")
# Assumes $15/GB/day ingest cost


# STRATEGY 2: OPTIMIZE RETENTION
# ════════════════════════════════════════════════════════════════════════════

# Different data types need different retention:
┌───────────────────────┬─────────────────┬────────────────────────────────────┐
│ Index                 │ Retention       │ Rationale                          │
├───────────────────────┼─────────────────┼────────────────────────────────────┤
│ security_events       │ 365 days        │ Compliance, investigation          │
│ pos_transactions      │ 90 days         │ Operational, fraud detection       │
│ endpoint_windows      │ 30 days         │ High volume, short-term value      │
│ network_firewall      │ 30 days         │ High volume, incident response     │
│ app_debug             │ 7 days          │ Troubleshooting only               │
│ summary_*             │ 365 days        │ Aggregated, low volume             │
└───────────────────────┴─────────────────┴────────────────────────────────────┘

# Use S3-based archival for long-term compliance (cheaper than searchable)


# STRATEGY 3: SUMMARY INDEXING
# ════════════════════════════════════════════════════════════════════════════

# Instead of searching 90 days of raw POS data, create daily summaries

# Scheduled search: Daily POS Summary (runs at 1am)
index=pos_transactions earliest=-1d@d latest=@d
| stats count as transactions,
        sum(amount) as total_revenue,
        dc(customer_id) as unique_customers,
        avg(response_time) as avg_response
by store_id, region, date=strftime(_time, "%Y-%m-%d")
| collect index=summary_pos sourcetype=pos:daily_summary

# Dashboard queries use summary index (100x faster):
index=summary_pos sourcetype=pos:daily_summary earliest=-90d
| stats sum(transactions) as total_txns, sum(total_revenue) as revenue by region


# STRATEGY 4: DATA MODEL ACCELERATION
# ════════════════════════════════════════════════════════════════════════════

# Accelerate frequently-used data models
# Settings → Data Models → Edit Acceleration

# Benefits:
# • Pre-computed summaries for fast searches
# • Automatic acceleration management
# • Optimized for tstats queries

# Accelerated query example:
| tstats count FROM datamodel=Authentication 
  WHERE nodename=Authentication.Failed_Authentication 
  BY Authentication.user, _time span=1h

# vs non-accelerated (10-100x slower):
index=security sourcetype=wineventlog EventCode=4625
| timechart span=1h count by user


# STRATEGY 5: SEARCH OPTIMIZATION
# ════════════════════════════════════════════════════════════════════════════

# Poor search (scans everything):
index=* error

# Better search (specific index and time):
index=pos_transactions status="error" earliest=-24h

# Best search (uses indexed fields first):
index=pos_transactions sourcetype=pos:transactions status="error" earliest=-24h
| fields store_id, transaction_id, error_message, _time


# COST MONITORING QUERIES
# ════════════════════════════════════════════════════════════════════════════

# Daily ingestion by sourcetype
index=_internal source=*license_usage.log type=Usage
| stats sum(b) as bytes by st
| eval GB = round(bytes/1024/1024/1024, 2)
| sort -GB

# Weekly trend
index=_internal source=*license_usage.log type=Usage earliest=-7d
| bin _time span=1d
| stats sum(b) as bytes by _time
| eval GB = round(bytes/1024/1024/1024, 2)
| timechart span=1d sum(GB) as daily_ingest</code></pre>
                    </div>
                </div>

                <!-- Migration Strategies -->
                <h2><i class="fas fa-exchange-alt"></i> Enterprise to Cloud Migration</h2>
                
                <div class="config-section">
                    <h3>Migration Planning & Execution</h3>
                    <div class="arch-diagram">
SPLUNK ENTERPRISE TO CLOUD MIGRATION
════════════════════════════════════════════════════════════════════════════════

PHASE 1: ASSESSMENT (2-4 weeks)
──────────────────────────────────────────────────────────────────────────────
□ Inventory current deployment
  ├── Daily ingest volume
  ├── Number of indexes
  ├── Installed apps
  ├── Custom knowledge objects
  └── User count and roles

□ Identify incompatibilities
  ├── Custom scripted inputs (need conversion)
  ├── Apps not Cloud-compatible
  ├── Direct filesystem access
  └── Custom authentication

□ Define success criteria
  ├── Zero data loss
  ├── Maximum acceptable downtime
  └── Performance benchmarks


PHASE 2: PREPARATION (4-8 weeks)
──────────────────────────────────────────────────────────────────────────────
□ Splunk Cloud provisioning
  ├── Choose deployment region (Canada for Sobeys - data residency)
  ├── Size based on current + growth
  └── Select support tier

□ Network preparation
  ├── Firewall rules for Cloud connectivity
  ├── VPN/PrivateLink if required
  └── DNS updates

□ App vetting
  ├── Submit apps for Cloud vetting
  ├── Identify alternatives for incompatible apps
  └── Rewrite scripted inputs for Cloud compatibility


PHASE 3: MIGRATION EXECUTION (2-4 weeks)
──────────────────────────────────────────────────────────────────────────────

Option A: Parallel Run (Recommended)
┌─────────────────────────────────────────────────────────────────────────────┐
│                                                                              │
│   Data Sources ─────┬────────▶ Enterprise (existing) ◀─── Users            │
│                     │                                      (validation)     │
│                     └────────▶ Cloud (new)           ◀─── Users            │
│                                                           (testing)         │
│                                                                              │
│   Benefits:                                                                  │
│   • Compare results side-by-side                                            │
│   • Users can validate before cutover                                       │
│   • Rollback possible                                                        │
│                                                                              │
│   Duration: 2-4 weeks parallel running                                      │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘

Option B: Big Bang (Faster, riskier)
┌─────────────────────────────────────────────────────────────────────────────┐
│                                                                              │
│   Weekend cutover:                                                           │
│   Friday PM:   Stop forwarders to Enterprise                                │
│   Saturday:    Reconfigure forwarders for Cloud                             │
│   Sunday:      Validation and testing                                        │
│   Monday AM:   Go-live with Cloud                                           │
│                                                                              │
│   Risk: Limited validation time                                              │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘


PHASE 4: KNOWLEDGE OBJECT MIGRATION
──────────────────────────────────────────────────────────────────────────────

Migration Order:
1. Lookups (export CSVs, import to Cloud)
2. Props/transforms (submit via support ticket)
3. Saved searches (export/import via CLI or API)
4. Dashboards (export XML, import to Cloud)
5. Alerts (recreate with updated indexes)
6. Users/roles (recreate or sync via SAML)

# Export saved searches from Enterprise
$SPLUNK_HOME/bin/splunk export saved-searches -app search -format csv > searches.csv

# Export dashboards
$SPLUNK_HOME/bin/splunk export dashboards -app search > dashboards.tar


PHASE 5: CUTOVER & VALIDATION
──────────────────────────────────────────────────────────────────────────────
□ Update forwarder outputs.conf to Cloud
□ Update HEC endpoints to Cloud
□ Validate data flow (volume comparison)
□ Validate search results (side-by-side)
□ Validate alert functionality
□ User acceptance testing
□ Decommission Enterprise (after validation period)


SOBEYS-SPECIFIC CONSIDERATIONS
──────────────────────────────────────────────────────────────────────────────
• Data Residency: Use Canadian Cloud region for PIPEDA compliance
• POS Data: Test HEC endpoints thoroughly (high volume, critical)
• SAP Integration: Validate Splunk Connect for SAP on Cloud
• Store Connectivity: Ensure all 1,500 store networks can reach Cloud
• Maintenance Windows: Align with lowest-traffic periods (Sunday 2-6 AM)
                    </div>
                </div>

                <!-- Monitoring & Health -->
                <h2><i class="fas fa-heartbeat"></i> Monitoring Splunk Cloud Health</h2>
                
                <div class="config-section">
                    <h3>Health Monitoring Queries</h3>
                    <div class="config-block">
                        <div class="config-block-header">
                            <span class="config-title">Cloud Health Dashboard Queries</span>
                        </div>
                        <pre><code># SPLUNK CLOUD HEALTH MONITORING
# ════════════════════════════════════════════════════════════════════════════

# 1. INGESTION HEALTH - Data arriving as expected
# ────────────────────────────────────────────────────────────────────────────
index=_internal source=*metrics.log group=per_sourcetype_thruput earliest=-24h
| eval GB = kb/1024/1024
| timechart span=1h sum(GB) as ingest_GB by series
| addtotals col=t row=f fieldname=total_GB

# Alert if ingestion drops > 50% from baseline
index=_internal source=*metrics.log group=per_sourcetype_thruput earliest=-1h
| stats sum(kb) as current_kb
| appendcols [search index=_internal source=*metrics.log group=per_sourcetype_thruput earliest=-25h latest=-24h | stats sum(kb) as baseline_kb]
| eval variance = round((current_kb - baseline_kb) / baseline_kb * 100, 1)
| where variance < -50


# 2. FORWARDER HEALTH - All forwarders connected
# ────────────────────────────────────────────────────────────────────────────
index=_internal sourcetype=splunkd group=tcpin_connections
| stats latest(_time) as last_seen, values(connectionType) as type by hostname, sourceIp
| eval hours_since_contact = round((now() - last_seen) / 3600, 1)
| where hours_since_contact > 1
| sort -hours_since_contact
| table hostname, sourceIp, type, hours_since_contact


# 3. SEARCH PERFORMANCE - Identify slow/expensive searches
# ────────────────────────────────────────────────────────────────────────────
index=_audit action=search info=completed earliest=-24h
| stats avg(total_run_time) as avg_time, 
        max(total_run_time) as max_time,
        sum(total_run_time) as total_time,
        count 
by user
| where avg_time > 60
| sort -total_time
| table user, count, avg_time, max_time, total_time


# 4. LICENSE UTILIZATION - Stay under limits
# ────────────────────────────────────────────────────────────────────────────
| rest /services/licenser/pools
| eval used_GB = round(used_bytes/1024/1024/1024, 2)
| eval quota_GB = round(effective_quota/1024/1024/1024, 2)
| eval pct_used = round(used_GB/quota_GB*100, 1)
| eval status = case(pct_used >= 90, "CRITICAL", pct_used >= 80, "WARNING", true(), "OK")
| table description, used_GB, quota_GB, pct_used, status


# 5. HEC TOKEN HEALTH - Monitor token usage
# ────────────────────────────────────────────────────────────────────────────
index=_internal sourcetype=splunkd_access uri="/services/collector*" earliest=-24h
| rex field=uri "token=(?<token_id>[^&]+)"
| stats count as requests,
        sum(eval(if(status=200,1,0))) as success,
        sum(eval(if(status!=200,1,0))) as errors
by token_id
| eval error_rate = round(errors/requests*100, 2)
| where error_rate > 5
| table token_id, requests, success, errors, error_rate


# 6. SCHEDULED SEARCH HEALTH - Jobs completing successfully
# ────────────────────────────────────────────────────────────────────────────
index=_internal sourcetype=scheduler status=* earliest=-24h
| stats count(eval(status="success")) as success,
        count(eval(status="skipped")) as skipped,
        count(eval(status="failed")) as failed,
        count(eval(status="deferred")) as deferred
by savedsearch_name, app
| where failed > 0 OR skipped > 5
| sort -failed
| table app, savedsearch_name, success, failed, skipped, deferred


# 7. INDEX HEALTH - Storage utilization
# ────────────────────────────────────────────────────────────────────────────
| rest /services/data/indexes 
| search disabled=0 totalEventCount>0
| eval size_GB = round(currentDBSizeMB/1024, 2)
| eval max_GB = round(maxTotalDataSizeMB/1024, 2)
| eval pct_used = round(currentDBSizeMB/maxTotalDataSizeMB*100, 1)
| sort -pct_used
| table title, size_GB, max_GB, pct_used, totalEventCount


# 8. ALERT TRIGGER HEALTH - Alerts firing as expected
# ────────────────────────────────────────────────────────────────────────────
index=_internal sourcetype=scheduler savedsearch_name=*alert* earliest=-24h
| stats count as triggers,
        latest(_time) as last_trigger
by savedsearch_name
| eval hours_since_trigger = round((now() - last_trigger) / 3600, 1)
| table savedsearch_name, triggers, hours_since_trigger</code></pre>
                    </div>
                </div>

                <!-- Interview Q&A -->
                <h2><i class="fas fa-comments"></i> Interview Questions</h2>
                
                <div class="qa-section">
                    <div class="qa-item">
                        <button class="qa-question">Q: What is the shared responsibility model in Splunk Cloud?</button>
                        <div class="qa-answer">
                            <p><strong>Customer Responsibilities:</strong></p>
                            <ul>
                                <li>Data onboarding (what data, how to collect)</li>
                                <li>Index and retention configuration</li>
                                <li>User access management and SAML setup</li>
                                <li>Knowledge objects, dashboards, alerts</li>
                                <li>App installation requests</li>
                                <li>Search optimization</li>
                            </ul>
                            <p><strong>Splunk Responsibilities:</strong></p>
                            <ul>
                                <li>Infrastructure (servers, network, storage)</li>
                                <li>Software upgrades and patches</li>
                                <li>Availability (SLA: 99.9% or 99.95%)</li>
                                <li>Security (encryption, vulnerability management)</li>
                                <li>Disaster recovery and backups</li>
                                <li>Compliance certifications (SOC 2, ISO 27001)</li>
                            </ul>
                        </div>
                    </div>

                    <div class="qa-item">
                        <button class="qa-question">Q: How would you reduce Splunk Cloud costs for a high-volume retail environment?</button>
                        <div class="qa-answer">
                            <p><strong>Immediate Actions:</strong></p>
                            <ol>
                                <li><strong>Use Ingest Actions</strong> to filter debug logs at ingestion (saves license)</li>
                                <li><strong>Reduce retention</strong> for high-volume, low-value data (e.g., 7 days for debug)</li>
                                <li><strong>Summary indexing</strong> for frequently-queried metrics</li>
                                <li><strong>Deduplicate sources</strong> - ensure data isn't sent multiple times</li>
                            </ol>
                            <p><strong>Medium-term Actions:</strong></p>
                            <ol>
                                <li><strong>Data model acceleration</strong> to reduce search compute</li>
                                <li><strong>Tune Windows Event collection</strong> - collect only security-relevant events</li>
                                <li><strong>Implement event sampling</strong> for non-critical verbose logs</li>
                                <li><strong>Archive to S3</strong> for long-term compliance (cheaper than searchable)</li>
                            </ol>
                        </div>
                    </div>

                    <div class="qa-item">
                        <button class="qa-question">Q: How do you troubleshoot data not arriving in Splunk Cloud?</button>
                        <div class="qa-answer">
                            <p><strong>Systematic Troubleshooting:</strong></p>
                            <ol>
                                <li><strong>Verify forwarder connectivity:</strong><br>
                                <code>index=_internal sourcetype=splunkd group=tcpin_connections | stats count by hostname</code></li>
                                <li><strong>Check for errors:</strong><br>
                                <code>index=_internal sourcetype=splunkd ERROR host=&lt;forwarder&gt;</code></li>
                                <li><strong>Verify certificates:</strong><br>
                                <code>openssl x509 -in cacert.pem -noout -dates</code></li>
                                <li><strong>Check firewall:</strong> Port 9997 (forwarders) or 8088 (HEC) open?</li>
                                <li><strong>For HEC:</strong> Verify token status via ACS API</li>
                                <li><strong>Check license:</strong> Not exceeded daily quota?</li>
                            </ol>
                        </div>
                    </div>
                </div>

                <!-- Related Resources -->
                <h2><i class="fas fa-link"></i> Related Resources</h2>
                <ul>
                    <li><a href="splunk-cloud.html">Splunk Cloud Overview</a></li>
                    <li><a href="data-ingestion.html">Data Ingestion Guide</a></li>
                    <li><a href="forwarders.html">Forwarder Management</a></li>
                    <li><a href="troubleshooting.html">General Troubleshooting</a></li>
                </ul>

            </main>
        </div>
    </div>
    
    <script>
        function toggleSidebar() {
            const sidebar = document.getElementById('sidebar');
            const mainWrapper = document.getElementById('mainWrapper');
            const overlay = document.getElementById('sidebarOverlay');
            
            if (window.innerWidth <= 768) {
                sidebar.classList.toggle('open');
                overlay.classList.toggle('active');
            } else {
                sidebar.classList.toggle('collapsed');
                mainWrapper.classList.toggle('expanded');
            }
        }
        
        document.querySelectorAll('.qa-question').forEach(btn => {
            btn.addEventListener('click', () => {
                const answer = btn.nextElementSibling;
                const isOpen = answer.style.display === 'block';
                document.querySelectorAll('.qa-answer').forEach(a => a.style.display = 'none');
                if (!isOpen) answer.style.display = 'block';
            });
        });
    </script>
</body>
</html>
