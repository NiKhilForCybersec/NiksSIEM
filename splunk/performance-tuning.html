<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Performance Tuning | Splunk</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="shared-styles.css">
    <link rel="stylesheet" href="../assets/css/main.css">


</head>
<body>
    <div class="app-container">
            <!-- Sidebar -->
        <!-- Sidebar -->
        <!-- Sidebar -->
            <aside class="sidebar" id="sidebar">
            <div class="sidebar-header">
                <a href="index.html" class="sidebar-logo"><i class="fas fa-terminal"></i><span>Splunk Reference</span></a>
            </div>
            <div class="sidebar-content">
                <div class="sidebar-section">
                    <div class="sidebar-section-title">Certifications</div>
                    <ul class="sidebar-nav">
                        <li class="sidebar-nav-item"><a href="power-user-certification.html" class="sidebar-nav-link"><i class="fas fa-user-graduate" style="color:#7ce38b"></i>Power User</a></li>
                        <li class="sidebar-nav-item"><a href="admin-certification.html" class="sidebar-nav-link"><i class="fas fa-user-cog" style="color:#f0883e"></i>Admin</a></li>
                        <li class="sidebar-nav-item"><a href="es-admin-certification.html" class="sidebar-nav-link"><i class="fas fa-shield-alt" style="color:#8957e5"></i>ES Admin</a></li>
                        <li class="sidebar-nav-item"><a href="cloud-admin-certification.html" class="sidebar-nav-link"><i class="fas fa-cloud" style="color:#39c5cf"></i>Cloud Admin</a></li>
                    </ul>
                </div>
                <div class="sidebar-section">
                    <div class="sidebar-section-title">SPL Learning</div>
                    <ul class="sidebar-nav">
                        <li class="sidebar-nav-item"><a href="when-to-use-what.html" class="sidebar-nav-link"><i class="fas fa-map-signs" style="color:#f0883e"></i>When to Use What</a></li>
                        <li class="sidebar-nav-item"><a href="spl-practice-questions.html" class="sidebar-nav-link"><i class="fas fa-tasks" style="color:#58a6ff"></i>Practice MCQs</a></li>
                        <li class="sidebar-nav-item"><a href="spl-advanced-mcqs.html" class="sidebar-nav-link"><i class="fas fa-brain" style="color:#a371f7"></i>Advanced MCQs</a></li>
                    </ul>
                </div>
                <div class="sidebar-section">
                    <div class="sidebar-section-title">SPL Reference</div>
                    <ul class="sidebar-nav">
                        <li class="sidebar-nav-item"><a href="spl-fundamentals.html" class="sidebar-nav-link"><i class="fas fa-code"></i>SPL Fundamentals</a></li>
                        <li class="sidebar-nav-item"><a href="spl-intermediate.html" class="sidebar-nav-link"><i class="fas fa-layer-group"></i>SPL Intermediate</a></li>
                        <li class="sidebar-nav-item"><a href="spl-advanced.html" class="sidebar-nav-link"><i class="fas fa-rocket"></i>SPL Advanced</a></li>
                        <li class="sidebar-nav-item"><a href="knowledge-objects.html" class="sidebar-nav-link"><i class="fas fa-lightbulb"></i>Knowledge Objects</a></li>
                        <li class="sidebar-nav-item"><a href="data-models.html" class="sidebar-nav-link"><i class="fas fa-cubes"></i>Data Models</a></li>
                    </ul>
                </div>
                <div class="sidebar-section">
                    <div class="sidebar-section-title">Administration</div>
                    <ul class="sidebar-nav">
                        <li class="sidebar-nav-item"><a href="architecture.html" class="sidebar-nav-link"><i class="fas fa-sitemap"></i>Architecture</a></li>
                        <li class="sidebar-nav-item"><a href="data-ingestion.html" class="sidebar-nav-link"><i class="fas fa-database"></i>Data Ingestion</a></li>
                        <li class="sidebar-nav-item"><a href="forwarders.html" class="sidebar-nav-link"><i class="fas fa-share-alt"></i>Forwarders</a></li>
                        <li class="sidebar-nav-item"><a href="clustering-ha.html" class="sidebar-nav-link"><i class="fas fa-network-wired"></i>Clustering & HA</a></li>
                    </ul>
                </div>
                <div class="sidebar-section">
                    <div class="sidebar-section-title">Enterprise Security</div>
                    <ul class="sidebar-nav">
                        <li class="sidebar-nav-item"><a href="es-overview.html" class="sidebar-nav-link"><i class="fas fa-shield-alt"></i>ES Overview</a></li>
                        <li class="sidebar-nav-item"><a href="correlation-searches.html" class="sidebar-nav-link"><i class="fas fa-search-plus"></i>Correlation Searches</a></li>
                        <li class="sidebar-nav-item"><a href="risk-based-alerting.html" class="sidebar-nav-link"><i class="fas fa-chart-line"></i>Risk-Based Alerting</a></li>
                    </ul>
                </div>
                <div class="sidebar-section">
                    <div class="sidebar-section-title">Resources</div>
                    <ul class="sidebar-nav">
                        <li class="sidebar-nav-item"><a href="lab-exercises.html" class="sidebar-nav-link"><i class="fas fa-flask"></i>Lab Exercises</a></li>
                        <li class="sidebar-nav-item"><a href="troubleshooting.html" class="sidebar-nav-link"><i class="fas fa-wrench"></i>Troubleshooting</a></li>
                    </ul>
                </div>
            </div>
        </aside>
    
    <div class="sidebar-overlay" id="sidebarOverlay" onclick="toggleSidebar()"></div>
        <div class="main-wrapper" id="mainWrapper">
            <button class="mobile-toggle" onclick="toggleSidebar()"><i class="fas fa-bars"></i></button>
            <main class="main-content">
                <div class="breadcrumb">
                    <a href="index.html">Home</a><span class="separator">/</span>
                    <a href="index.html">Splunk</a><span class="separator">/</span>
                    <span class="current">Performance Tuning</span>
                </div>

                <div class="hero-section">
                    <span class="version-badge">Splunk 9.x</span>
                    <h1 class="hero-title"><i class="fas fa-tachometer-alt" style="color: #3fb950;"></i> Performance Tuning</h1>
                    <p class="hero-subtitle">Optimize Splunk search performance, configure workload management, tune indexers, and implement capacity planning strategies.</p>
                </div>

                <h2><i class="fas fa-search"></i> Search Performance Optimization</h2>
                <div class="config-section">
                    <div class="arch-diagram">
SEARCH PERFORMANCE PRINCIPLES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

THE SEARCH PIPELINE:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Raw Data â†’ [Parsing] â†’ [Filtering] â†’ [Aggregation] â†’ [Formatting] â†’ Results

OPTIMIZATION GOAL: Reduce data at each stage as early as possible

KEY PRINCIPLES:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. TIME is the best filter - Always specify time range
2. INDEX is the second best filter - Be specific
3. Use INDEXED fields for filtering (host, source, sourcetype)
4. Filter BEFORE transforming (stats, eval, rex)
5. Use tstats for accelerated data models
6. Avoid wildcards at the beginning of terms

GOOD vs BAD SEARCHES:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BAD:  *error*
      â†’ Scans all data, wildcard at start

GOOD: index=app_logs sourcetype=myapp error
      â†’ Filters by index/sourcetype first, then keyword

BAD:  index=* | search user=admin
      â†’ Searches all indexes, filters late

GOOD: index=security user=admin
      â†’ Filters at index level immediately

BAD:  index=web | regex _raw=".*failed.*login.*"
      â†’ regex is expensive, runs on all events

GOOD: index=web "failed" "login" | regex _raw="failed.*login"
      â†’ Keywords filter first, regex on smaller dataset
                    </div>

                    <h3>Search Command Optimization</h3>
                    <div class="arch-diagram">
COMMAND PERFORMANCE TIERS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

TIER 1 - DISTRIBUTABLE/STREAMING (Fast)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Commands that run on indexers, reduce data early:
â€¢ search, where, eval, fields, rename, rex, regex
â€¢ stats, timechart, chart (aggregation phase)
â€¢ head, tail (streaming phase)

TIER 2 - CENTRALIZED (Slower)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Commands that run only on search head:
â€¢ sort (full dataset must come to SH)
â€¢ dedup (requires full dataset comparison)
â€¢ transaction (complex event grouping)
â€¢ join (expensive, use alternatives)
â€¢ append (runs multiple searches)

TIER 3 - VERY EXPENSIVE (Avoid if possible)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ join â†’ Use stats, OR conditions, or lookups instead
â€¢ transaction â†’ Use stats with values() or list()
â€¢ append â†’ Combine into single search if possible

COMMAND ALTERNATIVES:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Instead of:                       Use:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
| join type=left field           | lookup table.csv field OUTPUT newfield
| transaction by session_id      | stats values(*) by session_id
| append [search index=b]        | (index=a) OR (index=b)
| sort - count | head 10         | stats count | sort 10 -count
| table field | dedup field      | stats first(*) by field
                    </div>
                </div>

                <h2><i class="fas fa-layer-group"></i> Workload Management</h2>
                <div class="config-section">
                    <div class="arch-diagram">
WORKLOAD MANAGEMENT ARCHITECTURE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚          WORKLOAD MANAGEMENT           â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                             â–¼                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   WORKLOAD    â”‚           â”‚   WORKLOAD    â”‚           â”‚   WORKLOAD    â”‚
â”‚    POOL 1     â”‚           â”‚    POOL 2     â”‚           â”‚    POOL 3     â”‚
â”‚   (Ad-Hoc)    â”‚           â”‚  (Scheduled)  â”‚           â”‚   (Premium)   â”‚
â”‚               â”‚           â”‚               â”‚           â”‚               â”‚
â”‚ CPU: 30%      â”‚           â”‚ CPU: 50%      â”‚           â”‚ CPU: 20%      â”‚
â”‚ Mem: 30%      â”‚           â”‚ Mem: 50%      â”‚           â”‚ Mem: 20%      â”‚
â”‚ Concurrent: 5 â”‚           â”‚ Concurrent: 10â”‚           â”‚ Concurrent: 3 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â–²                             â–²                             â–²
        â”‚                             â”‚                             â”‚
    Standard                      Scheduled                     Admin
    Users                         Searches                      Users

WORKLOAD RULES:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Rules map searches to pools based on:
â€¢ User/Role
â€¢ App
â€¢ Search type (ad-hoc, scheduled, realtime)
â€¢ Index being searched
                    </div>

                    <h3>Workload Configuration</h3>
                    <div class="arch-diagram">
# /opt/splunk/etc/system/local/workload_pools.conf

[workload_pool:adhoc_pool]
cpu_weight = 30
mem_weight = 30
default_category = search

[workload_pool:scheduled_pool]
cpu_weight = 50
mem_weight = 50
default_category = scheduled

[workload_pool:premium_pool]
cpu_weight = 20
mem_weight = 20
default_category = search

# /opt/splunk/etc/system/local/workload_rules.conf

[workload_rule:admin_searches]
predicate = role=admin
workload_pool = premium_pool
schedule_priority = highest
search_time_limit = 0

[workload_rule:scheduled_searches]
predicate = search_type=scheduled
workload_pool = scheduled_pool
schedule_priority = default
search_time_limit = 3600

[workload_rule:adhoc_default]
predicate = search_type=adhoc
workload_pool = adhoc_pool
schedule_priority = default
search_time_limit = 600
                    </div>
                </div>

                <h2><i class="fas fa-database"></i> Indexer Performance</h2>
                <div class="config-section">
                    <div class="arch-diagram">
INDEXER TUNING PARAMETERS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# /opt/splunk/etc/system/local/server.conf

[general]
parallelIngestionPipelines = 2    # Default: 1, increase for high volume

[queue]
maxSize = 500MB                   # Parsing queue size

[queue=indexQueue]
maxSize = 500MB                   # Index queue size

# /opt/splunk/etc/system/local/indexes.conf

[default]
maxHotSpanSecs = 3600             # Max time span of hot bucket (1 hour)
maxHotBuckets = 10                # Max hot buckets per index
maxDataSize = auto_high_volume    # Bucket size strategy
maxWarmDBCount = 300              # Number of warm buckets

DISK PERFORMANCE:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Hot buckets: SSD/NVMe required
Warm buckets: SSD preferred, fast HDD acceptable
Cold buckets: HDD acceptable
Frozen: Archive storage (S3, tape)

RECOMMENDED DISK LAYOUT:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
/opt/splunk/var/lib/splunk/
â”œâ”€â”€ hot/              # NVMe or SSD RAID
â”‚   â””â”€â”€ db/
â”œâ”€â”€ warm/             # SSD RAID
â”‚   â””â”€â”€ db/
â””â”€â”€ cold/             # HDD RAID
    â””â”€â”€ db/

# indexes.conf with separate paths
[myindex]
homePath = /opt/splunk/var/lib/splunk/hot/myindex/db
coldPath = /opt/splunk/var/lib/splunk/cold/myindex/colddb
thawedPath = /opt/splunk/var/lib/splunk/thawed/myindex/thaweddb
                    </div>
                </div>

                <h2><i class="fas fa-memory"></i> Memory and CPU Tuning</h2>
                <div class="config-section">
                    <div class="arch-diagram">
SEARCH HEAD MEMORY CONFIGURATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# /opt/splunk/etc/system/local/limits.conf

[search]
max_searches_per_cpu = 4          # Concurrent searches per CPU core
base_max_searches = 6             # Base concurrent searches
max_mem_usage_mb = 4000           # Max memory per search

[searchresults]
maxresultrows = 50000             # Max result rows
maxresults = 10000000             # Max events in results

[realtime]
max_rt_search_multiplier = 1      # Limit real-time searches

MEMORY CALCULATION:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total Search Memory = max_mem_usage_mb Ã— max_concurrent_searches

Example: 4GB Ã— 20 searches = 80GB needed for search
Add: OS overhead, JVM, indexing = ~100GB RAM recommended

INDEXER MEMORY:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# server.conf
[kvstore]
maxMemoryUsageMB = 8192           # KV Store memory limit

# limits.conf
[indexer]
max_disk_usage_percent = 90       # Stop ingesting at 90% disk
                    </div>
                </div>

                <h2><i class="fas fa-project-diagram"></i> Performance Decision Trees</h2>
                <div class="config-section">
                    <h3>Decision Tree: Slow Search Troubleshooting</h3>
                    <div class="arch-diagram">
Decision Tree: Diagnosing Slow Searches
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

START: Search is slow - where's the bottleneck?
â”‚
â”œâ”€â–º Check Job Inspector (Job â†’ Inspect Job)
â”‚   â”‚
â”‚   â”œâ”€â–º [High scan count, low event count]
â”‚   â”‚   Problem: Search not filtering efficiently
â”‚   â”‚   Fix: Add time range, use indexed fields
â”‚   â”‚        Move filters to beginning of search
â”‚   â”‚
â”‚   â”œâ”€â–º [Long execution time in "dispatch" phase]
â”‚   â”‚   Problem: Indexer saturation
â”‚   â”‚   Fix: Check indexer CPU/IO, spread search across time
â”‚   â”‚
â”‚   â”œâ”€â–º [Long time in "combiner" or "reduce"]
â”‚   â”‚   Problem: Too much data returning to search head
â”‚   â”‚   Fix: Add aggregations earlier, use tstats
â”‚   â”‚
â”‚   â””â”€â–º [Long time in specific command]
â”‚       Problem: Expensive command (join, transaction)
â”‚       Fix: Replace with efficient alternatives
â”‚
â”œâ”€â–º Check Search Peer Status
â”‚   â”‚
â”‚   â”œâ”€â–º Indexers responding slowly?
â”‚   â”‚   â†’ Check indexer CPU, memory, disk I/O
â”‚   â”‚   â†’ Use Monitoring Console for per-peer metrics
â”‚   â”‚
â”‚   â””â”€â–º Indexers not responding?
â”‚       â†’ Network issue or indexer down
â”‚       â†’ Check cluster status
â”‚
â””â”€â–º Check System Resources (MC)
    â”‚
    â”œâ”€â–º CPU maxed? â†’ Too many concurrent searches
    â”‚               â†’ Implement workload management
    â”‚
    â”œâ”€â–º Memory pressure? â†’ Reduce max_mem_usage_mb
    â”‚                    â†’ Add more RAM
    â”‚
    â””â”€â–º Disk I/O saturated? â†’ Upgrade to SSD
                             â†’ Spread indexes across disks
                    </div>
                </div>

                <div class="config-section">
                    <h3>Decision Tree: Capacity Planning</h3>
                    <div class="arch-diagram">
Decision Tree: Sizing Splunk Infrastructure
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

START: What's your daily ingest volume?
â”‚
â”œâ”€â–º [<50 GB/day] â†’ Single server deployment
â”‚   Specs: 8 cores, 32 GB RAM, 1 TB SSD
â”‚   
â”œâ”€â–º [50-200 GB/day] â†’ Small distributed
â”‚   â€¢ 1 Search Head: 8 cores, 32 GB, 500 GB SSD
â”‚   â€¢ 2-3 Indexers: 8 cores each, 32 GB, 2 TB SSD each
â”‚   
â”œâ”€â–º [200-500 GB/day] â†’ Medium distributed
â”‚   â€¢ 3 Search Head Cluster
â”‚   â€¢ 4-6 Indexers in cluster (RF=2)
â”‚   â€¢ Heavy Forwarders for aggregation
â”‚   
â”œâ”€â–º [500 GB - 1 TB/day] â†’ Large distributed
â”‚   â€¢ 5 Search Head Cluster
â”‚   â€¢ 8-12 Indexers (RF=3)
â”‚   â€¢ Multiple Heavy Forwarder tiers
â”‚   â€¢ Dedicated Cluster Manager
â”‚   
â””â”€â–º [>1 TB/day] â†’ Enterprise scale
    â€¢ Multiple Search Head Clusters
    â€¢ 15+ Indexers (RF=3)
    â€¢ Data Stream Processor consideration
    â€¢ SmartStore for cost optimization

SIZING FORMULAS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Indexers = (Daily GB Ã— Retention Days Ã— Compression Ã— RF) / Usable Storage
         = (500 Ã— 90 Ã— 0.5 Ã— 3) / 4000 GB = ~17 indexers

Search Heads = Concurrent Users / 30-50 users per SH
             = 150 users / 40 = ~4 search heads
                    </div>
                </div>

                <h2><i class="fas fa-exclamation-circle"></i> What Enterprises Usually Miss</h2>
                <div class="enterprise-gap-grid">
                    <div class="gap-card gap-critical">
                        <h4>ğŸ”´ Critical Gaps</h4>
                        <ul>
                            <li><strong>No workload management:</strong> All searches compete equally, one bad search affects everyone</li>
                            <li><strong>Undersized indexers:</strong> Not enough I/O capacity for ingest + search simultaneously</li>
                            <li><strong>No search time limits:</strong> Runaway searches consume all resources</li>
                            <li><strong>Real-time search abuse:</strong> Too many real-time searches killing performance</li>
                        </ul>
                    </div>
                    <div class="gap-card gap-warning">
                        <h4>ğŸŸ¡ Common Oversights</h4>
                        <ul>
                            <li><strong>Hot buckets on HDD:</strong> Using spinning disk for hot data</li>
                            <li><strong>No data model acceleration:</strong> Not leveraging tstats for fast searches</li>
                            <li><strong>Unoptimized scheduled searches:</strong> Running expensive searches hourly</li>
                            <li><strong>Missing summary indexing:</strong> Recalculating same aggregations repeatedly</li>
                        </ul>
                    </div>
                    <div class="gap-card gap-info">
                        <h4>ğŸ”µ Often Overlooked</h4>
                        <ul>
                            <li><strong>Search scheduling collision:</strong> All scheduled searches at top of hour</li>
                            <li><strong>No search quotas per user:</strong> Single user can run unlimited searches</li>
                            <li><strong>Lookup file bloat:</strong> Giant CSV lookups slowing searches</li>
                            <li><strong>Unused indexes:</strong> Searching indexes with no relevant data</li>
                        </ul>
                    </div>
                    <div class="gap-card gap-best-practice">
                        <h4>ğŸŸ¢ Best Practices Often Skipped</h4>
                        <ul>
                            <li><strong>Regular search review:</strong> No audit of expensive scheduled searches</li>
                            <li><strong>Capacity headroom:</strong> Running at 90%+ with no room for growth</li>
                            <li><strong>Performance baselines:</strong> No documented baseline metrics</li>
                            <li><strong>Search optimization training:</strong> Users write inefficient searches</li>
                        </ul>
                    </div>
                </div>

                <h2><i class="fas fa-comments"></i> Interview Questions & Answers</h2>
                <div class="qa-section">
                    <div class="qa-item">
                        <button class="qa-question">Q: How do you optimize a slow search that's taking 30 minutes to complete?</button>
                        <div class="qa-answer">
                            <div class="arch-diagram">
SEARCH OPTIMIZATION PROCESS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

STEP 1: Analyze with Job Inspector
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Job â†’ Inspect Job â†’ Look at:
â€¢ scanCount (events scanned) vs resultCount (returned)
â€¢ Time spent in each phase
â€¢ Memory usage

STEP 2: Common Fixes
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Problem: scanCount 500M, resultCount 1000
Fix: Add filters early
     BEFORE: index=* | search error | stats count
     AFTER:  index=app_logs error | stats count

Problem: Long time in "join" command
Fix: Replace with lookup or stats
     BEFORE: index=web | join session_id [search index=auth]
     AFTER:  index=web OR index=auth | stats values(*) by session_id

Problem: 30-day search on non-accelerated data
Fix: Use accelerated data model + tstats
     BEFORE: index=security | stats count by src_ip
     AFTER:  | tstats count from datamodel=Network_Traffic by src_ip

STEP 3: Structural Improvements
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Create summary index for repeated aggregations
â€¢ Accelerate relevant data models
â€¢ Pre-calculate with scheduled report
â€¢ Add relevant fields to index-time extraction

EXPECTED IMPROVEMENT:
30 min â†’ 5 min with filters
5 min â†’ 30 sec with tstats
                            </div>
                        </div>
                    </div>

                    <div class="qa-item">
                        <button class="qa-question">Q: Explain workload management and how you'd configure it for a SOC.</button>
                        <div class="qa-answer">
                            <div class="arch-diagram">
SOC WORKLOAD MANAGEMENT DESIGN
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

POOL ALLOCATION:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Critical_Alerts (20% CPU/Memory)
   â€¢ Real-time correlation searches
   â€¢ Priority: Highest
   â€¢ Time limit: None

2. Scheduled_Searches (40% CPU/Memory)
   â€¢ Scheduled reports, dashboards
   â€¢ Priority: Default
   â€¢ Time limit: 1 hour

3. Analyst_Interactive (30% CPU/Memory)
   â€¢ SOC analyst ad-hoc searches
   â€¢ Priority: Default
   â€¢ Time limit: 30 minutes

4. General_Users (10% CPU/Memory)
   â€¢ Non-SOC users
   â€¢ Priority: Low
   â€¢ Time limit: 10 minutes

RULES:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[workload_rule:critical_rt]
predicate = (search_type=realtime AND app=SplunkEnterpriseSecuritySuite)
workload_pool = critical_alerts

[workload_rule:soc_analysts]
predicate = (role=soc_analyst AND search_type=adhoc)
workload_pool = analyst_interactive

[workload_rule:scheduled]
predicate = search_type=scheduled
workload_pool = scheduled_searches

BENEFIT: SOC searches protected from user queries impacting performance
                            </div>
                        </div>
                    </div>

                    <div class="qa-item">
                        <button class="qa-question">Q: How do you size a Splunk deployment for 500 GB/day ingestion?</button>
                        <div class="qa-answer">
                            <div class="arch-diagram">
SIZING FOR 500 GB/DAY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ASSUMPTIONS:
â€¢ 90-day hot/warm retention
â€¢ RF=3, SF=2 for high availability
â€¢ 100 concurrent users
â€¢ 50% average compression

STORAGE CALCULATION:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Raw storage = 500 GB Ã— 90 days Ã— 0.5 (compression) Ã— 3 (RF)
            = 67.5 TB

Per indexer (8 TB usable): 67.5 / 8 = ~9 indexers
Add 20% headroom: 11 indexers

INDEXER SPECS (each):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ CPU: 16 cores
â€¢ RAM: 64 GB
â€¢ Hot/Warm: 2 TB NVMe
â€¢ Cold: 6 TB SSD

SEARCH HEAD SIZING:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
100 users / ~30 per SH = 4 search heads (SHC)

SH Specs (each):
â€¢ CPU: 16 cores
â€¢ RAM: 64 GB
â€¢ Disk: 500 GB SSD

ADDITIONAL COMPONENTS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ 1 Cluster Manager
â€¢ 1 Deployer
â€¢ 1 License Manager
â€¢ 2-4 Heavy Forwarders (for aggregation)
â€¢ 1 Monitoring Console

TOTAL: ~18-20 servers
                            </div>
                        </div>
                    </div>

                    <div class="qa-item">
                        <button class="qa-question">Q: What's the difference between tstats and regular stats? When would you use each?</button>
                        <div class="qa-answer">
                            <div class="arch-diagram">
TSTATS vs STATS COMPARISON
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

STATS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Operates on raw events
â€¢ Searches _raw data and extracts fields
â€¢ Slow for large datasets
â€¢ Works on any field

Example:
index=security | stats count by src_ip, dest_ip

TSTATS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Operates on tsidx (indexed metadata)
â€¢ Uses accelerated data models or indexed fields
â€¢ 10-100x faster than stats
â€¢ Only works with indexed/accelerated fields

Example:
| tstats count FROM datamodel=Network_Traffic BY src, dest

WHEN TO USE EACH:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

USE TSTATS WHEN:
âœ“ Data model exists and is accelerated
âœ“ Fields are in metadata (host, source, sourcetype, _time)
âœ“ High-volume searches (millions of events)
âœ“ Dashboard panels (need fast response)
âœ“ Regular scheduled searches

USE STATS WHEN:
âœ“ Need fields not in data model
âœ“ One-time ad-hoc analysis
âœ“ Complex field extractions required
âœ“ Data model not available

PERFORMANCE EXAMPLE:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Search: Count by source IP over 30 days, 100M events

stats:  index=security | stats count by src_ip
        â†’ 25 minutes, scans all raw data

tstats: | tstats count FROM datamodel=Network_Traffic BY src
        â†’ 15 seconds, reads only tsidx
                            </div>
                        </div>
                    </div>
                </div>

                <h2><i class="fas fa-link"></i> Related Resources</h2>
                <ul>
                    <li><a href="monitoring-console.html">Monitoring Console</a></li>
                    <li><a href="troubleshooting.html">Troubleshooting</a></li>
                    <li><a href="administration.html">Administration</a></li>
                    <li><a href="data-models.html">Data Models</a></li>
                </ul>
            </main>
        </div>
    </div>
    <script>
        function toggleSidebar() {
            const sidebar = document.getElementById('sidebar');
            const mainWrapper = document.getElementById('mainWrapper');
            const overlay = document.getElementById('sidebarOverlay');
            if (window.innerWidth <= 768) { sidebar.classList.toggle('open'); overlay.classList.toggle('active'); } 
            else { sidebar.classList.toggle('collapsed'); mainWrapper.classList.toggle('expanded'); }
        }
        document.querySelectorAll('.qa-question').forEach(btn => {
            btn.addEventListener('click', () => {
                const answer = btn.nextElementSibling;
                const isOpen = answer.style.display === 'block';
                document.querySelectorAll('.qa-answer').forEach(a => a.style.display = 'none');
                if (!isOpen) answer.style.display = 'block';
            });
        });
    </script>
</body>
</html>
